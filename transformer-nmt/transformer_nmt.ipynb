{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from evaluate import load, combine\n",
    "from tqdm import tqdm\n",
    "    \n",
    "from transformer import *\n",
    "from dataset import *\n",
    "\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7150\n",
      "50257\n",
      "cuda\n",
      "en ob\n"
     ]
    }
   ],
   "source": [
    "# get data \n",
    "train = load_dataset('csv', data_files='../data/train.csv')['train']\n",
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "VAL_CUTOFF = 500 # random choice for val loss, full test set is 3110, take 500 away for validation only. \n",
    "val = test[:VAL_CUTOFF]\n",
    "test = test[VAL_CUTOFF:]\n",
    "\n",
    "\n",
    "# obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/obolo-bpe-tokenizer.json', padding='left')\n",
    "obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/obolo-bpe-tokenizer-small.json', padding='left')\n",
    "# obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/obolo-wordpiece-tokenizer-small.json', padding='left')\n",
    "# obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/custom_plus_bpe_obolo_tokenizer/tokenizer.json', padding='left')\n",
    "english_tokenizer = AutoTokenizer.from_pretrained('gpt2', padding='left')\n",
    "\n",
    "# print(obolo_tokenizer.vocab_size)\n",
    "print(len(obolo_tokenizer))\n",
    "# print(english_tokenizer.vocab_size)\n",
    "print(len(english_tokenizer))\n",
    "print(DEVICE)\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "# token_transform[SRC_LANGUAGE] = obolo_tokenizer\n",
    "# token_transform[TGT_LANGUAGE] = english_tokenizer\n",
    "\n",
    "# vocab_transform[SRC_LANGUAGE] = obolo_tokenizer.vocab \n",
    "# vocab_transform[TGT_LANGUAGE] = english_tokenizer.vocab\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'ob'\n",
    "token_transform[SRC_LANGUAGE] = english_tokenizer\n",
    "token_transform[TGT_LANGUAGE] = obolo_tokenizer\n",
    "\n",
    "vocab_transform[SRC_LANGUAGE] = english_tokenizer.vocab \n",
    "vocab_transform[TGT_LANGUAGE] = english_tokenizer.vocab\n",
    "\n",
    "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#   vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "init_text_transform(token_transform, SRC_LANGUAGE, TGT_LANGUAGE)\n",
    "# now this BPE tokenizer is also equipped with a decoder, so we should be able to do Obolo -> English and English -> Obolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ob_sent, en_sent = train['Obolo'][0], train['English'][0]\n",
    "# print(ob_sent)\n",
    "# print(obolo_tokenizer(ob_sent))\n",
    "# print(text_transform[SRC_LANGUAGE](ob_sent))\n",
    "# print(obolo_tokenizer(ob_sent)['input_ids'] == list(text_transform[SRC_LANGUAGE](ob_sent))[1:-1])\n",
    "# print(en_sent)\n",
    "# print(text_transform[TGT_LANGUAGE](en_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(token_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(token_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# train_dataloader = generate_dataloader(train['Obolo'], train['English'], BATCH_SIZE)\n",
    "# val_dataloader = generate_dataloader(val['Obolo'], val['English'], BATCH_SIZE)\n",
    "# test_dataloader = generate_dataloader(test['Obolo'], test['English'], BATCH_SIZE)\n",
    "train_dataloader = generate_dataloader(train['English'], train['Obolo'], BATCH_SIZE)\n",
    "val_dataloader = generate_dataloader(val['English'], val['Obolo'], BATCH_SIZE)\n",
    "test_dataloader = generate_dataloader(test['English'], test['Obolo'], BATCH_SIZE)\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=7150, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(7150, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.98)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-09\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transformer)\n",
    "display(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.783, Val loss: 3.865, Epoch time = 97.225s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 3.651, Val loss: 3.388, Epoch time = 95.152s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 3.276, Val loss: 3.111, Epoch time = 95.390s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 3.021, Val loss: 2.914, Epoch time = 97.120s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 2.822, Val loss: 2.778, Epoch time = 96.121s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 2.659, Val loss: 2.669, Epoch time = 95.430s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 2.522, Val loss: 2.576, Epoch time = 97.233s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 2.403, Val loss: 2.514, Epoch time = 95.285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 2.298, Val loss: 2.468, Epoch time = 95.975s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 2.203, Val loss: 2.415, Epoch time = 98.047s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 2.116, Val loss: 2.395, Epoch time = 96.367s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 2.035, Val loss: 2.355, Epoch time = 97.248s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 1.958, Val loss: 2.342, Epoch time = 97.195s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 1.891, Val loss: 2.304, Epoch time = 97.514s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 1.826, Val loss: 2.294, Epoch time = 97.311s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.762, Val loss: 2.287, Epoch time = 96.595s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 1.706, Val loss: 2.280, Epoch time = 95.481s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 1.651, Val loss: 2.266, Epoch time = 95.282s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 1.598, Val loss: 2.263, Epoch time = 97.553s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 1.548, Val loss: 2.270, Epoch time = 95.397s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 1.502, Val loss: 2.287, Epoch time = 95.431s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 1.456, Val loss: 2.293, Epoch time = 95.565s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 1.410, Val loss: 2.297, Epoch time = 95.274s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 1.367, Val loss: 2.310, Epoch time = 95.193s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 1.328, Val loss: 2.297, Epoch time = 94.998s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 1.285, Val loss: 2.312, Epoch time = 95.343s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 1.247, Val loss: 2.323, Epoch time = 95.472s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 1.211, Val loss: 2.344, Epoch time = 95.284s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 1.175, Val loss: 2.352, Epoch time = 95.608s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 1.141, Val loss: 2.357, Epoch time = 95.249s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 1.109, Val loss: 2.381, Epoch time = 95.147s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 1.077, Val loss: 2.393, Epoch time = 94.778s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 1.045, Val loss: 2.400, Epoch time = 94.925s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 1.013, Val loss: 2.430, Epoch time = 95.158s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 0.984, Val loss: 2.441, Epoch time = 95.094s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 0.957, Val loss: 2.458, Epoch time = 94.944s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 0.930, Val loss: 2.481, Epoch time = 97.127s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 0.900, Val loss: 2.509, Epoch time = 96.888s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 0.875, Val loss: 2.520, Epoch time = 96.005s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 0.849, Val loss: 2.549, Epoch time = 96.287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 0.823, Val loss: 2.570, Epoch time = 95.383s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 0.800, Val loss: 2.587, Epoch time = 97.360s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 0.777, Val loss: 2.608, Epoch time = 97.962s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:28<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 0.754, Val loss: 2.618, Epoch time = 97.172s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 0.732, Val loss: 2.644, Epoch time = 95.936s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 0.708, Val loss: 2.658, Epoch time = 96.518s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 0.690, Val loss: 2.682, Epoch time = 95.571s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 0.672, Val loss: 2.694, Epoch time = 95.476s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:26<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 0.652, Val loss: 2.716, Epoch time = 95.358s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:27<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.636, Val loss: 2.733, Epoch time = 96.494s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# NUM_EPOCHS = 10\n",
    "NUM_EPOCHS = 50 \n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if epoch % 5 == 0:\n",
    "        # torch.save(transformer, f'checkpoints/transformer_obolo_to_english_bpe_{epoch}_epochs.pt')\n",
    "        torch.save(transformer, f'checkpoints/transformer_english_to_obolo_bpe_small_{epoch}_epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAHFCAYAAACuBbDPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABYFUlEQVR4nO3dd3hUdf728fek995JCCGhBQWkCoqAKAKCiLq6igrYFSy77upawbKiuz6WVdey9hVlfxYURVCQqtJrpLckQAhppJN+nj9OMjAkSIBJJpncr+uaayZnzsx8cozJzbdaDMMwEBEREbEDF0cXICIiIs5DwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQpqMxWJp1G3JkiVn9TnTp0/HYrGc0WuXLFlilxpaukmTJtGhQ4eTPp+dnY2Hhwd//OMfT3pOYWEhPj4+XHHFFY3+3A8//BCLxUJqamqjazmexWJh+vTpjf68OhkZGUyfPp2NGzfWe+5sfl7OVocOHRgzZoxDPlukubg5ugBxXitWrLD5+plnnmHx4sUsWrTI5nhycvJZfc5tt93GyJEjz+i1vXv3ZsWKFWddQ2sXHh7OFVdcwddff82RI0cIDg6ud86sWbM4evQot95661l91hNPPMH9999/Vu9xKhkZGTz11FN06NCBXr162Tx3Nj8vInJqChbSZM4//3ybr8PDw3Fxcal3/ESlpaX4+Pg0+nNiY2OJjY09oxoDAgJOWU9bceutt/Lll18yc+ZMpk6dWu/5999/n8jISC6//PKz+pzExMSzev3ZOpufFxE5NXWFiEMNHTqUc845h2XLljFo0CB8fHy45ZZbAPjf//7HiBEjiI6Oxtvbm27duvG3v/2NkpISm/doqGm7rsl5/vz59O7dG29vb7p27cr7779vc15DXSGTJk3Cz8+P3bt3M3r0aPz8/IiLi+PBBx+kvLzc5vUHDhzgmmuuwd/fn6CgICZMmMCaNWuwWCx8+OGHv/u9Z2dnc88995CcnIyfnx8RERFcfPHFLF++3Oa81NRULBYLL774Ii+99BIJCQn4+fkxcOBAVq5cWe99P/zwQ7p06YKnpyfdunXj448//t066lx22WXExsbywQcf1Htu27ZtrFq1iptvvhk3NzcWLFjAuHHjiI2NxcvLi6SkJO68805ycnJO+TkNdYUUFhZy++23Exoaip+fHyNHjmTnzp31Xrt7924mT55Mp06d8PHxoV27dowdO5aUlBTrOUuWLKFfv34ATJ482drlVtel0tDPS01NDf/4xz/o2rUrnp6eREREcPPNN3PgwAGb8+p+XtesWcPgwYPx8fGhY8eOPP/889TU1Jzye2+MsrIyHnnkERISEvDw8KBdu3ZMmTKF/Px8m/MWLVrE0KFDCQ0Nxdvbm/bt23P11VdTWlpqPefNN9+kZ8+e+Pn54e/vT9euXXn00Udt3iczM5M777yT2NhYPDw8SEhI4KmnnqKqqsrmvMa8lwioxUJagEOHDnHjjTfy0EMP8dxzz+HiYubdXbt2MXr0aB544AF8fX3Zvn07L7zwAqtXr67XndKQTZs28eCDD/K3v/2NyMhI3n33XW699VaSkpK46KKLfve1lZWVXHHFFdx66608+OCDLFu2jGeeeYbAwECefPJJAEpKShg2bBh5eXm88MILJCUlMX/+fK677rpGfd95eXkATJs2jaioKIqLi5k9ezZDhw7lp59+YujQoTbnv/HGG3Tt2pVXXnkFMLsURo8ezb59+wgMDATMUDF58mTGjRvH//t//4+CggKmT59OeXm59bqejIuLC5MmTeLZZ59l06ZN9OzZ0/pcXdioC3179uxh4MCB3HbbbQQGBpKamspLL73EhRdeSEpKCu7u7o26BgCGYXDllVfy66+/8uSTT9KvXz9++eUXRo0aVe/cjIwMQkNDef755wkPDycvL4+PPvqIAQMGsGHDBrp06ULv3r354IMPmDx5Mo8//ri1heX3Winuvvtu3nnnHaZOncqYMWNITU3liSeeYMmSJaxfv56wsDDruZmZmUyYMIEHH3yQadOmMXv2bB555BFiYmK4+eabG/19/961+Omnn3jkkUcYPHgwmzdvZtq0aaxYsYIVK1bg6elJamoql19+OYMHD+b9998nKCiIgwcPMn/+fCoqKvDx8WHWrFncc8893Hvvvbz44ou4uLiwe/dutm7davO99O/fHxcXF5588kkSExNZsWIFzz77LKmpqdb/7o15LxErQ6SZTJw40fD19bU5NmTIEAMwfvrpp999bU1NjVFZWWksXbrUAIxNmzZZn5s2bZpx4o9yfHy84eXlZaSlpVmPHT161AgJCTHuvPNO67HFixcbgLF48WKbOgHj//7v/2zec/To0UaXLl2sX7/xxhsGYMybN8/mvDvvvNMAjA8++OB3v6cTVVVVGZWVlcbw4cON8ePHW4/v27fPAIxzzz3XqKqqsh5fvXq1ARifffaZYRiGUV1dbcTExBi9e/c2ampqrOelpqYa7u7uRnx8/Clr2Lt3r2GxWIz77rvPeqyystKIiooyLrjgggZfU/ffJi0tzQCMb775xvrcBx98YADGvn37rMcmTpxoU8u8efMMwHj11Vdt3vfvf/+7ARjTpk07ab1VVVVGRUWF0alTJ+NPf/qT9fiaNWtO+t/gxJ+Xbdu2GYBxzz332Jy3atUqAzAeffRR67G6n9dVq1bZnJucnGxcdtllJ62zTnx8vHH55Zef9Pn58+cbgPGPf/zD5vj//vc/AzDeeecdwzAM44svvjAAY+PGjSd9r6lTpxpBQUG/W8+dd95p+Pn52fx/YhiG8eKLLxqAsWXLlka/l0gddYWIwwUHB3PxxRfXO753715uuOEGoqKicHV1xd3dnSFDhgBm0/yp9OrVi/bt21u/9vLyonPnzqSlpZ3ytRaLhbFjx9oc69Gjh81rly5dir+/f72BgNdff/0p37/OW2+9Re/evfHy8sLNzQ13d3d++umnBr+/yy+/HFdXV5t6AGtNO3bsICMjgxtuuMGmqT8+Pp5BgwY1qp6EhASGDRvGzJkzqaioAGDevHlkZmZaWysAsrKyuOuuu4iLi7PWHR8fDzTuv83xFi9eDMCECRNsjt9www31zq2qquK5554jOTkZDw8P3Nzc8PDwYNeuXaf9uSd+/qRJk2yO9+/fn27duvHTTz/ZHI+KiqJ///42x0782ThTdS1xJ9byhz/8AV9fX2stvXr1wsPDgzvuuIOPPvqIvXv31nuv/v37k5+fz/XXX88333zTYDfVd999x7Bhw4iJiaGqqsp6q2stWrp0aaPfS6SOgoU4XHR0dL1jxcXFDB48mFWrVvHss8+yZMkS1qxZw1dffQXA0aNHT/m+oaGh9Y55eno26rU+Pj54eXnVe21ZWZn169zcXCIjI+u9tqFjDXnppZe4++67GTBgAF9++SUrV65kzZo1jBw5ssEaT/x+PD09gWPXIjc3FzD/8J2ooWMnc+utt5Kbm8ucOXMAsxvEz8+Pa6+9FjDHI4wYMYKvvvqKhx56iJ9++onVq1dbx3s05voeLzc3Fzc3t3rfX0M1//nPf+aJJ57gyiuv5Ntvv2XVqlWsWbOGnj17nvbnHv/50PDPYUxMjPX5Omfzc9WYWtzc3AgPD7c5brFYiIqKstaSmJjIwoULiYiIYMqUKSQmJpKYmMirr75qfc1NN93E+++/T1paGldffTUREREMGDCABQsWWM85fPgw3377Le7u7ja37t27A1gDRGPeS6SOxliIwzW0psCiRYvIyMhgyZIl1lYKoN4ANkcKDQ1l9erV9Y5nZmY26vWffPIJQ4cO5c0337Q5XlRUdMb1nOzzG1sTwFVXXUVwcDDvv/8+Q4YM4bvvvuPmm2/Gz88PgN9++41Nmzbx4YcfMnHiROvrdu/efcZ1V1VVkZuba/NHu6GaP/nkE26++Waee+45m+M5OTkEBQWd8eeDOdbnxHEYGRkZNuMrmlrdtcjOzrYJF4ZhkJmZaR2UCjB48GAGDx5MdXU1a9eu5bXXXuOBBx4gMjLSuh7J5MmTmTx5MiUlJSxbtoxp06YxZswYdu7cSXx8PGFhYfTo0YO///3vDdYTExNjfXyq9xKpoxYLaZHqwkbdv8rrvP32244op0FDhgyhqKiIefPm2RyfNWtWo15vsVjqfX+bN2+ut/5HY3Xp0oXo6Gg+++wzDMOwHk9LS+PXX39t9Pt4eXlxww038OOPP/LCCy9QWVlp0w1i7/82w4YNA2DmzJk2xz/99NN65zZ0zebOncvBgwdtjp3YmvN76rrhPvnkE5vja9asYdu2bQwfPvyU72EvdZ91Yi1ffvklJSUlDdbi6urKgAEDeOONNwBYv359vXN8fX0ZNWoUjz32GBUVFWzZsgWAMWPG8Ntvv5GYmEjfvn3r3Y4PFqd6L5E6arGQFmnQoEEEBwdz1113MW3aNNzd3Zk5cyabNm1ydGlWEydO5OWXX+bGG2/k2WefJSkpiXnz5vHDDz8AnHIWxpgxY3jmmWeYNm0aQ4YMYceOHTz99NMkJCTUm+rXGC4uLjzzzDPcdtttjB8/nttvv538/HymT59+Wl0hYHaHvPHGG7z00kt07drVZoxG165dSUxM5G9/+xuGYRASEsK33357xs3iI0aM4KKLLuKhhx6ipKSEvn378ssvv/Df//633rljxozhww8/pGvXrvTo0YN169bxz3/+s15LQ2JiIt7e3sycOZNu3brh5+dHTExMg38ou3Tpwh133MFrr72Gi4sLo0aNss4KiYuL409/+tMZfV8nk5mZyRdffFHveIcOHbj00ku57LLLePjhhyksLOSCCy6wzgo577zzuOmmmwBzbM6iRYu4/PLLad++PWVlZdap1JdccgkAt99+O97e3lxwwQVER0eTmZnJjBkzCAwMtLZ8PP300yxYsIBBgwZx33330aVLF8rKykhNTeX777/nrbfeIjY2tlHvJWLl4MGj0oacbFZI9+7dGzz/119/NQYOHGj4+PgY4eHhxm233WasX7++3mj/k80KaWj0/ZAhQ4whQ4ZYvz7ZrJAT6zzZ56SnpxtXXXWV4efnZ/j7+xtXX3218f3339ebHdGQ8vJy4y9/+YvRrl07w8vLy+jdu7fx9ddf15s1UTcr5J///Ge996CBWRPvvvuu0alTJ8PDw8Po3Lmz8f7779d7z8Y477zzGpyhYBiGsXXrVuPSSy81/P39jeDgYOMPf/iDkZ6eXq+exswKMQzDyM/PN2655RYjKCjI8PHxMS699FJj+/bt9d7vyJEjxq233mpEREQYPj4+xoUXXmgsX7683n9XwzCMzz77zOjatavh7u5u8z4N/Xesrq42XnjhBaNz586Gu7u7ERYWZtx4443G/v37bc472c9rY69vfHy8ATR4mzhxomEY5uylhx9+2IiPjzfc3d2N6Oho4+677zaOHDlifZ8VK1YY48ePN+Lj4w1PT08jNDTUGDJkiDFnzhzrOR999JExbNgwIzIy0vDw8DBiYmKMa6+91ti8ebNNTdnZ2cZ9991nJCQkGO7u7kZISIjRp08f47HHHjOKi4tP671EDMMwLIZxXJupiJy15557jscff5z09HSt8CgibY66QkTOwuuvvw6Y3QOVlZUsWrSIf/3rX9x4440KFSLSJilYiJwFHx8fXn75ZVJTUykvL6d9+/Y8/PDDPP74444uTUTEIdQVIiIiInaj6aYiIiJiNwoWIiIiYjcKFiIiImI3zT54s6amhoyMDPz9/RtcyllERERaHsMwKCoqIiYm5ncXAGz2YJGRkUFcXFxzf6yIiIjYwf79+393On2zBwt/f3/ALCwgIKC5P15ERETOQGFhIXFxcda/4yfT7MGirvsjICBAwUJERKSVOdUwBg3eFBEREbtRsBARERG7UbAQERERu9FeISIi4jSqq6uprKx0dBmtkru7O66urmf9PgoWIiLS6hmGQWZmJvn5+Y4upVULCgoiKirqrNaZUrAQEZFWry5URERE4OPjowUYT5NhGJSWlpKVlQVAdHT0Gb+XgoWIiLRq1dXV1lARGhrq6HJaLW9vbwCysrKIiIg4424RDd4UEZFWrW5MhY+Pj4Mraf3qruHZjFNRsBAREaeg7o+zZ49rqGAhIiIidqNgISIi4gQ6dOjAK6+84ugyNHhTRETEUYYOHUqvXr3sEgjWrFmDr6/v2Rd1lpymxaLgaCW7DhdRWV3j6FJERETswjAMqqqqGnVueHh4ixjA6jTBYtCMn7j05WUcOHLU0aWIiIic0qRJk1i6dCmvvvoqFosFi8XChx9+iMVi4YcffqBv3754enqyfPly9uzZw7hx44iMjMTPz49+/fqxcOFCm/c7sSvEYrHw7rvvMn78eHx8fOjUqRNz5sxp8u/LaYJFZIAXAIcLyxxciYiIOJphGJRWVDX7zTCMRtf46quvMnDgQG6//XYOHTrEoUOHiIuLA+Chhx5ixowZbNu2jR49elBcXMzo0aNZuHAhGzZs4LLLLmPs2LGkp6f/7mc89dRTXHvttWzevJnRo0czYcIE8vLyzuranorTjLGICPBkb04JWUXlji5FREQc7GhlNclP/tDsn7v16cvw8Wjcn9bAwEA8PDzw8fEhKioKgO3btwPw9NNPc+mll1rPDQ0NpWfPntavn332WWbPns2cOXOYOnXqST9j0qRJXH/99QA899xzvPbaa6xevZqRI0ee9vfWWE7XYpGlFgsREWnl+vbta/N1SUkJDz30EMnJyQQFBeHn58f27dtP2WLRo0cP62NfX1/8/f2ty3Y3FedpsfD3BNQVIiIi4O3uytanL3PI59rDibM7/vrXv/LDDz/w4osvkpSUhLe3N9dccw0VFRW/+z7u7u42X1ssFmpqmnaSg9MEi2NjLNQVIiLS1lkslkZ3STiSh4cH1dXVpzxv+fLlTJo0ifHjxwNQXFxMampqE1d3ZpymKySiriukSC0WIiLSOnTo0IFVq1aRmppKTk7OSVsTkpKS+Oqrr9i4cSObNm3ihhtuaPKWhzPlPMGitiskSy0WIiLSSvzlL3/B1dWV5ORkwsPDTzpm4uWXXyY4OJhBgwYxduxYLrvsMnr37t3M1TaOxTiduTF2UFhYSGBgIAUFBQQEBNjtfffllDDsxSX4eriy5emmG+0qIiItS1lZGfv27SMhIQEvLy9Hl9Oq/d61bOzfb6drsSipqKa4vHGrlImIiIh9OU2w8PV0w8/THKijKaciIiKO4TTBAsxFskAzQ0RERBzFqYJFpL9mhoiIiDiSUwWLuhYLzQwRERFxDKcKFtqITERExLGcKlhY17LQRmQiIiIO4VzBQi0WIiIiDuVUwSJSLRYiIiIO5VzBQi0WIiLShnTo0IFXXnnF0WXYcKpgUTcrpFSrb4qIiDiEUwULHw83/GtX31SrhYiISPNzqmABx6++qWAhIiIt19tvv027du3qbX9+xRVXMHHiRPbs2cO4ceOIjIzEz8+Pfv36sXDhQgdV23jOFyxqV9/M1gBOEZG2yzCgoqT5b6exYfgf/vAHcnJyWLx4sfXYkSNH+OGHH5gwYQLFxcWMHj2ahQsXsmHDBi677DLGjh170q3VWwo3Rxdgb5FqsRARkcpSeC6m+T/30Qzw8G3UqSEhIYwcOZJPP/2U4cOHA/D5558TEhLC8OHDcXV1pWfPntbzn332WWbPns2cOXOYOnVqk5RvD07XYnFsZohaLEREpGWbMGECX375JeXl5t+smTNn8sc//hFXV1dKSkp46KGHSE5OJigoCD8/P7Zv364Wi+ZWt0iW1rIQEWnD3H3M1gNHfO5pGDt2LDU1NcydO5d+/fqxfPlyXnrpJQD++te/8sMPP/Diiy+SlJSEt7c311xzDRUVFU1Rud04X7DwV1eIiEibZ7E0ukvCkby9vbnqqquYOXMmu3fvpnPnzvTp0weA5cuXM2nSJMaPHw9AcXExqampDqy2cZwuWNR1hWQpWIiISCswYcIExo4dy5YtW7jxxhutx5OSkvjqq68YO3YsFouFJ554ot4MkpbICcdYHFvW2ziN0bkiIiKOcPHFFxMSEsKOHTu44YYbrMdffvllgoODGTRoEGPHjuWyyy6jd+/eDqy0cZyuxaJuumnd6pv+Xu4OrkhEROTkXF1dycioPx6kQ4cOLFq0yObYlClTbL5uiV0jTtdi4e3hir9X3eqbGsApIiLSnJwuWMBx4yyKNM5CRESkOTllsKibGZKlFgsREZFm5ZTBQtuni4iIOIZTBotjG5GpxUJEpK3QTMCzZ49r6JzBwl9jLERE2gp3d3P2X2lpqYMraf3qrmHdNT0TTjfdFI5by0ItFiIiTs/V1ZWgoCCysrIA8PHxwWKxOLiq1sUwDEpLS8nKyiIoKAhXV9czfi8nDRa1YyzUYiEi0iZERUUBWMOFnJmgoCDrtTxTThksjp8VYhiGkquIiJOzWCxER0cTERFBZWWlo8tpldzd3c+qpaKOkwYLs8XiaGU1ReVVBGj1TRGRNsHV1dUufxzlzDnl4E1vD1cCalff1GZkIiIizccpgwVAhHWXUw3gFBERaS5OGyzqZoZoAKeIiEjzcd5g4V+3+qZaLERERJqL0waLcK1lISIi0uycNlhYWyzUFSIiItJsnDdYWAdvKliIiIg0FycOFrVdIUXqChEREWkuThssIvyPbZ2uHe9ERESah/MGi9oWi7LKGgrLqhxcjYiISNvgtMHCy92VQG9zKW+NsxAREWkeThss4LjNyDTOQkREpFk4dbCwbp+uFgsREZFm4dTBom6chVbfFBERaR7OHSxqZ4ZkaZEsERGRZuHUwSJSy3qLiIg0KycPFhpjISIi0pycOlhoVoiIiEjzcupgcXyLhVbfFBERaXpOHSzCa1ssyqtqKDyq1TdFRESa2lkFixkzZmCxWHjggQfsVI592ay+qZkhIiIiTe6Mg8WaNWt455136NGjhz3rsbtIrWUhIiLSbM4oWBQXFzNhwgT+85//EBwcbO+a7EozQ0RERJrPGQWLKVOmcPnll3PJJZec8tzy8nIKCwttbs0pXDNDREREmo3b6b5g1qxZrF+/njVr1jTq/BkzZvDUU0+ddmH2ohYLERGR5nNaLRb79+/n/vvv55NPPsHLy6tRr3nkkUcoKCiw3vbv339GhZ6pSGuLhYKFiIhIUzutFot169aRlZVFnz59rMeqq6tZtmwZr7/+OuXl5bi6utq8xtPTE09PT/tUewYirC0W6goRERFpaqcVLIYPH05KSorNscmTJ9O1a1cefvjheqGiJbDuF6IWCxERkSZ3WsHC39+fc845x+aYr68voaGh9Y63FHU7nB4uLMcwDCwWi4MrEhERcV5OvfImQERti0VFVQ0FRysdXI2IiIhzO+1ZISdasmSJHcpoOp5urgT5uJNfWklWUTlBPh6OLklERMRpOX2LBUCkv6acioiINIc2ESwitKy3iIhIs2gbwaK2xUIzQ0RERJqWcwSLyjL4Zgq8MQAqSuo9bZ1yqhYLERGRJuUcwcLNE/YshuztcGBtvae1rLeIiEjzcI5gYbFA+4Hm4/QV9Z6O0EZkIiIizcI5ggVAfG2wSPu13lMRarEQERFpFs4TLNoPMu8PrIFq24Wwjh9jYRhGc1cmIiLSZjhPsAjvCl5BUFkKhzbbPlXbFVJRXUN+qVbfFBERaSrOEyxcXKD9+ebjdNvuEE83V4J93AGNsxAREWlKzhMs4NgAzrT6Azg1M0RERKTpOVewiK8dZ5G+Ak4YS1HXHaJgISIi0nScK1hE9wI3bziaBzk7bZ6qa7FQV4iIiEjTca5g4eYBsX3NxydMOz02M0QtFiIiIk3FuYIFnHShrAjrDqdqsRAREWkqzhcs4hsewGltsdBGZCIiIk3G+YJFbH+wuEJBOhQcsB4+tvqmWixERESaivMFC08/iO5hPj6u1aJuv5DsIq2+KSIi0lScL1jAseW9j1soS6tvioiIND3nDBYNjLPwdHMlxNcDgMMaZyEiItIknDNY1M0Myd4GpXnWwxHWRbI0zkJERKQpOGew8A2D0E7m4/SV1sN1i2Sl55U6oioRERGn55zBAo51hxw3zqJvfDAAS3dkOaIiERERp+e8wcI6gPNYi8XwbpEA/Lw7h6MV1Y6oSkRExKk5b7Coa7HI2AAVZtdHt2h/2gV5U1ZZwy+7cxxYnIiIiHNy3mARFA/+MVBTBQfXAmCxWLikWwQAP20/7MjqREREnJLzBguLpcFpp3XdIQu3ZVFTo4WyRERE7Ml5gwUctyHZsQGcAzqG4OfpRnZROSkHCxxUmIiIiHNy7mARXzuAc/8aqK4CzIWyLuocBsDCbeoOERERsSfnDhbh3cArCCpLIHOT9fAltd0hC7YqWIiIiNiTcwcLFxdof775+LhxFsO6ROBige2ZRRw4osWyRERE7MW5gwUcN87iWLAI9vWgb3wIAD9t02JZIiIi9uL8waJunEX6Cjhuu/RLks1ppxpnISIiYj/OHyyie4GbF5TmQs5O6+G6aacr9+ZSVKZt1EVEROzB+YOFmwe062s+Tjs27TQx3I+OYb5UVhss36VVOEVEROzB+YMFHLch2Qqbw8NrV+FcqNkhIiIidtE2gkUDAzjh2LTTxTuyqKquae6qREREnE7bCBZx/cHiAvnpUHDQerhPfDBBPu4cKa1kfXq+4+oTERFxEm0jWHj6Q1QP8/FxrRZuri4M61K7KZlmh4iIiJy1thEs4Ni00+MGcMJxq3AqWIiIiJy1thMsTjLO4qLOYbi7WtibXcLe7GIHFCYiIuI82l6wyNoKpXnWw/5e7pzfMRTQKpwiIiJnq+0EC79wCO1kPj6hO2R4V3OchbpDREREzk7bCRYASZeY95s+szlctwrnurQjHCmpaO6qREREnEbbChZ9Jpn3O763mXYaF+JD1yh/qmsMluxUd4iIiMiZalvBIqIrxF8IRg2s/8jmqbrZIQs1zkJEROSMta1gAdDvFvN+3UdQfWzzsUuSzWCxdEc2FVVahVNERORMtL1g0XUs+EZAcabZJVKrR7tAwv09KS6vYvW+vN95AxERETmZthcs3Dyg903m4zXvWg+7uFiss0MWanaIiIjIGWl7wQJqB3FaYN8yyNllPTzcOs7iMIZhOKY2ERGRVqxtBoug9tD5MvPx2vethy9MCsPTzYUDR46y43CRg4oTERFpvdpmsADod5t5v3EmVJQC4O3hyuBOYQD8uEXdISIiIqer7QaLxOEQFA9lBbDlK+vhUedEA/DZ6nQqqzU7RERE5HS03WDh4gJ9J5uP17xnPTymZzRhfp4cKijj+5RDDipORESkdWq7wQLgvJvA1QMy1sPB9QB4urly88B4AN77eZ8GcYqIiJyGth0sfMMgeZz5eO2xVosJA9rj4ebC5gMFrE074qDiREREWp+2HSwA+t5q3qd8CUfNEBHq58nVvdsB8O7yvY6qTEREpNVRsGh/PkQkQ9VR2DTLeviWCxIA+HHrYdJySxxVnYiISKuiYGGxQL/aVou170PtmIpOkf4M6RyOYcAHv6Q6rj4REZFWRMECoMd14OEHOTshdbn18G2DzVaL/1u7n4KjlSd7tYiIiNRSsADw9Ice15qPj9s/5MKkMLpE+lNaUc3/1qQ7qDgREZHWQ8GiTt0gzu1zoSgTAIvFwq0Xmq0WH/6SqgWzRERETkHBok7UORA3AGqqYP3H1sNX9IohzM+DjIIy5v2W6cACRUREWj4Fi+PVtVqs+xCqqwDwcnflpvM7APDe8r1aMEtEROR3KFgcL3kceIdA4UHYOd96eML55oJZmw4UsE4LZomIiJyUgsXx3L2g903m46UvQE01AGF+nlx1Xt2CWfscVZ2IiEiLp2BxokH3gWcgZG6GDZ9YD99SO4jzh62ZpOeWOqo6ERGRFk3B4kS+YTD0YfPxomegrBCAzpH+XFS3YNavarUQERFpiIJFQ/rdDqFJUJINy/5pPXxbbavF/63RglkiIiINUbBoiJsHXPac+Xjlm5C7B4DBncLoHOlHiRbMEhERadBpBYs333yTHj16EBAQQEBAAAMHDmTevHlNVZtjdRoBicOhphJ+fAKov2BWlRbMEhERsXFawSI2Npbnn3+etWvXsnbtWi6++GLGjRvHli1bmqo+x7FYYOQMsLjCjrmwZzEA43q1I9RXC2aJiIg05LSCxdixYxk9ejSdO3emc+fO/P3vf8fPz4+VK1c2VX2OFd4F+t9uPp7/CFRXmQtmDYwH4N9L9lBdowWzRERE6pzxGIvq6mpmzZpFSUkJAwcOPOl55eXlFBYW2txalSEPg3cwZG+DdR8AcPPADvh7ubHtUCFfrNvv4AJFRERajtMOFikpKfj5+eHp6cldd93F7NmzSU5OPun5M2bMIDAw0HqLi4s7q4KbnU8IDHvMfLz4OTh6hBBfD+4f3gmAf/6wk6IyzRARERGBMwgWXbp0YePGjaxcuZK7776biRMnsnXr1pOe/8gjj1BQUGC97d/fCv+F32cyhHeDo3mw5AXAbLVICPMlp7icfy/Z4+ACRUREWgaLcZa7al1yySUkJiby9ttvN+r8wsJCAgMDKSgoICAg4Gw+unntWQz/vRJc3ODuFRDemYVbD3Pbx2vxcHXhpweHEBfi4+gqRUREmkRj/36f9ToWhmFQXl5+tm/T8iUOgy6jzW3Vf3gUgOHdIrgwKYyK6hpmzNvm4AJFREQc77SCxaOPPsry5ctJTU0lJSWFxx57jCVLljBhwoSmqq9lGfEsuLjD7gWw80csFguPj+mGiwW+T8lk5d5cR1coIiLiUKcVLA4fPsxNN91Ely5dGD58OKtWrWL+/PlceumlTVVfyxKaCOffZT7+4VGorqRrVADX928PwDPfbdX0UxERadPOeozF6Wq1YyzqlBXAa33MfURG/B0GTSW3uJyhLy6hqKyKf1zdg2v7tbKZLyIiIqfQbGMs2hyvQLjYXOKbn56C9FWE+nlap5/+44cdFJdXObBAERERx1GwOBPn3QRdx0B1Bcy6AfLTuXlgBzqE+pjTTxfvdnSFIiIiDqFgcSZcXGD82xB1LpTmwKfX4VFdwmOXmwuFvfvzPvbnlTq4SBERkeanYHGmPP3g+lngFwlZW+HL27ikSygXJIVSUaXppyIi0jYpWJyNwFj442fg5gU752P5aTpPjEm2Tj9dpemnIiLSxihYnK3YPjDuDfPxr6/RNeNr6/TTpzX9VERE2hgFC3s49xoY8jfz8Xd/5qGuOfh7urElo5Av1x9wbG0iIiLNSMHCXoY8DN3HQ00lgXNu4bGBXgD8Y/528koqHFyciIhI81CwsBcXFxj3b4g5D47mcd3uv9Iz3EJOcQWPfLWZZl6HTERExCEULOzJw8cczOkfgyVnB58EvoWXaw0/bDnM5+vUJSIiIs5PwcLeAqLh+s/AzRv/A0v5PH4OYPDUnC2k52ptCxERcW4KFk0hphdc9Q4A52b8H2+G/I/Sikr+/H8bNUtEREScmoJFU0m+Asa8DFgYVTqH/+f5HuvTcnlr6R5HVyYiItJkFCyaUt9bYPxbYHHhKstiXnF/g9cWbCXlQIGjKxMREWdkGFDi2MUZ3Rz66W1Bzz+CuzfGF7dyBSvwooK/zvJm9n0X4+3h6ujqRESkNaosg7w9kLMLcndBzu5j9+WF8NghcPd2SGkKFs0heRyWP3pj/O9GRrAOr4KneHFuME+M7+voykREpCWrroKcnXBoE2RuhuwdZoDI3w+cbMyeBfLTIbxLc1ZqpWDRXDqPwDLhc6o//SMXkYLnhiks7/QZg8/p6OjKRESkJagsg6wtcGjzsSBxeAtUlTV8vlcghHaCsE4QmlR73wlCOoK7V/PWfhwFi+bUcQiuN39N2YfjGcB2fvvyWo5Ef09waISjKxMRkaZUXQnFh6EoE4oO1d5nHvu68KDZrWFU13+thx9E9YDoHhDRDcI6mwHCNwwslub/Xk7BYjTzkpCFhYUEBgZSUFBAQEBAc350i1Gevp6yD64g0Chiv0cisffNx+KncCEi4hRKcuDgOjiwFg6uhcwUKMlu3Gt9QiG6Z22Q6GneghPM1Z0drLF/v9Vi4QCe7XuTftVXlH/xB+Iq9lD45ggCbp0NIQmOLk1ERE5HZZnZZVEXIg6shfy0hs91cQO/KPCvu0WDf2TtfRSEd4OAmBbZCnE6FCwcpNO5/fkk/QOGrb6NdiX7qH57KK7XfQwdhzi6NBERqWMYUJoLR9LMwJCfftx9OuTtg5rK+q8L7QSxfaFdH2jXG4LiwTukRbQ8NDV1hThQdY3BPW/N5e7MJ+nlsgfD4opl1AvQ77ZWn1hFRFqdqgqz22L/Sti/ypyBkZ8OlafYjsEnrDZE9IXYPuZmlN7BzVNzM1JXSCvg6mLh2Zsu5drX3Zha+hpXu/4M3//F/MEe/SK4eTi6RBER51WaB/tXmyFi/ypzXESDMzAsZndFUPtjt+D42vsE817/GLRSsHCwcH9P3pg4iKvfNNhe2Z5H3Gfhsv4jc97ytf8Fv3BHlygi0vpUlJiDKEtyzIGTpbX3JTlQnGVO58zZUf913sEQN8C8RfeE4A4QGAtuns3+LbRWChYtQHJMAC9fdx53fVLDLiOWd3z+jUf6CvjPMPjjp+YUIxERsVVTbY5xOJxirveQ+RtkbzODw6m6L+qEdjJDRPsBEHe+uR5EGxgH0ZQ0xqIFee2nXfy/BTvp7JLBN2Fv4F24D9x94Mp/Q/fxji5PRMRxSnIhe7sZIOqCRNa23w8Qbl7gG25O4fQNN9d98A0zx0SEdTYDhW9o830PrZzGWLRCUy9OYmdWMd9ugsuKnuSH9h/hnb4EPp8Eh7fC0L+Bi/YXEREnVVNtDpbM2WV2U+TsNB9n74CjeQ2/xs3bXDQq6hyIPAciu0NAOzNAePhp7IMDqMWihTlaUc21b68g5WAB3SJ8+KbrAjxWv2E+Gd4NLn0aOl2q/1lEpPUyDHPFybrWh8zfzNaH3N1QXX7y1wW2N4NDZPdjQSKko/7B1Uwa+/dbwaIFyiwo44rXfyarqJxLukXwTs/duMz/G5TlmyckDIERz5gDi0REWrKqitoujN/MAHG49lZ6kq29XT2P7XsR3sXssqjbC8PDt3lrFxsKFq3cxv35XPv2Ciqqarh7aCIPD4mE5f8PVr0N1RWABXpcBxc/DkFxji5XRMRUXWXOuNi3FPYtg/SVUHW0/nkWF3PgZF3rQ0R3CO9sLiSlFogWScHCCXyz8SD3z9oIwMvX9WT8ebHm6m+LnoGUz82TXD1h4D1w4Z/Mne5ERJpTTY25I+e+5WaQSPsFygttz/EKhMhzbcdBRHQDd2/H1CxnRMHCSfxj/nb+vWQPHm4uzLxtAP06hJhPHFwPPz4BaT+bX/uEwpCHoc8kzbcWEfupKDGnbxZnmbtzFh8214MoPgyFh+DAmvoDK70CocNgSLjIvIV31bgwJ6Bg4SRqagzu/GQdC7Yexs/TjZm3DaBnXJD5pGHAzvmw4Elz9DSYa9H3usEMGGGdHFW2iLQ2hmHugZH2K6T+AgdWQ2EGVBSf+rXuvhA/qDZIDDZ35lR3htNRsHAiZZXVTPpgNSv35hHo7c6sO86nW/Rx1666CtZ/ZI7BKDx47HiHwWbA6DZWrRgiYsswzFkYab+YQSLtVyg80PC5bt7gFwF+kcfdR5orA0ckmxttubo3b/3S7BQsnExxeRU3vbeKDen5hPl5MOuOgSRF+NmeVFMNuxbAug9h1w9g1JjH1YohIhUl5qDKg+vN7ou0X6Eky/YcFzeI6Q0dLoD2gyA00QwSWg9CULBwSgVHK7nhPyvZklFIVIAXn981kLgQn5OcfAA2fALrP7ZtxYi/EAbcAV3HatlaEWdVVWFO6cxYDwc3mPfZ24/9Y6OOqyfE9jO7MTpcALH9weMkv1OkzVOwcFJ5JRVc9/YKdmUVExvszed3DSQ68HdGVp+sFSO0E1z4AJx7rXZRFWmtqirgSCrk7jK7NXJ2QdZWc4fk6or65/tHmy0S7c4zWyTa9QF3r2YvW1onBQsnllVYxrVvryA1t5SOYb78786BhPs3YgxFwUFY9wGsfgfKCsxjAbEwaCr0vlmLz4i0NIZhbu1dnGmuVJmfBjm7jwWJI2lgVDf8Wq8gaNe7NkjU3gdEN2v54lwULJzcwfyjXPvWCg7mH6VrlD+f3X4+wb6NbHkoL4K1H8CK180pY2BOVx1wN/S/zdw2WESaR/5+cwDlkVQzPNRN6Syqva+p/P3Xe/iZYyFCa1enDO8MMedBcILGRYhdKVi0Aak5JVz79gqyisrpERvIJ7cNIMDrNEZmV5bBpk/hl1fNX2pg/pLqe4s50DM4QeMwROytJMdcSKpuZcq8vad+jU8o+EVBYDszQIQlHQsS/lEKENIsFCzaiF2Hi7junZXklVTQNz6Yj2/tj4/HaW5aW10FW7+G5S+ZK+jVcfc1V8eLTDaX243oZq6Y5xtm1+9BxKmVFZozMOrCxOHfbJ+3uJjdFJHdzZDgF1l7HwX+keAboXFQ0iIoWLQhWzIKuP6dlRSWVdE3Ppj3JvUj0PsM5pQbBuz8AX59zVwcp6HBX2D+ootMNn8Zdr/SXAxH/2ISZ2cY5kaAhYegKMO8L840xyuVFZr35YX1v64qq/9eEd2h4xBzQan4QVqOX1oFBYs2ZkP6ESa+v5rCsiq6RQfw8S39Gzeg82SqKyF3j9mCkbUNDm81H9d1mRwvrDOccw2ce43Z1yvSWtXUmAMjD64zp2cWHoKiQ+aU7cJDDW+m1RjBCWaI6DgEOlxkLiwl0sooWLRB2w4VctN7q8kpLqdDqA//vXXAyde5OFPlxZC9wwwZu38ylxQ//l9kMefBuX+A7ldpBLq0bIZhLll9cJ15q1vzoaLo91/nHQwB7cypm/6R5teegeAVYLY8eAac8DgQvIOa5VsSaUoKFm1UWm4JN763iv15R4kM8OSTWwfQKdK/6T6wrBC2z4XfvoA9i4+b+maBDhdC8jizRSMw1vxlrDnz0hQMAyqPml0V5UXm/hYVJcdu5UXHfV0EuXvNMFGcWf+93H0guhdEnWsOlvSPMUNyQIwZJrQjp7RRChZt2OHCMm56bxU7DxcT5OPOh5P706tu47KmVJxtDgJN+QL2r2z4HJ8wM2TUBY3AdhAYZ+5rouZhOZFhmN0QmSnmwk8luWZ4OHrkuFvt19Xlp//+FldzvFC7PrXrPfQxd+J0Pc0B0CJtgIJFG5dfWsGkD9awcX8+Ph6uvHNTXy7s1IyzOfLT4bcvYe9Sc3nxggO/3z9tcTHDRffx5qZpmnnS9lRXmrv0ZqbU3jab90ePNP49XNzA09+cNu3h28C9L3j6mS0P7fqYA4+1hLVIoyhYCCXlVdz533X8vDsHD1cX/nV9L0ae46BxD4Zh/oEoOGD+C7QubBQeNAfJZaYcO9fiag50636luaeJb6hjahb7qaowN7w6fuGn4iyzK6I4ywyi2dsbnolkcTVbESK7m10S3sHmqpLewcfdar/WZlkiTUbBQgAor6rmgVkbmfdbJi4WeP6qHlzbL87RZdWXt8/sRtky29yBsY7F1RxJ33282VTtG24uFqSmavuorjQHMNYFvYL9tYEvw/yXfEBtV1Vg7LFuK5/Q+n+8qyrM1x5JrX8rOABH8xpXj4e/Obbh+Ft4V43NEWkBFCzEqrrG4NGvUvjf2v0APDSyC3cPScTSUv9ll7cXtnxthozMzQ2cYAGfEDNk+Iab3Sa+EbWhI+TYKHyv4OMeB4LrGazt0RIZhjkTp7zYHIhYXmwOVqy7rzxqdjtVltXeH/+4zDyn6JD5B78oEzjNXwFuXrWBI9bc1O5IqtnydOLOmSdycTMXf/KLMBd/8ouoXQgqwuyaiEiGoHit9irSQilYiA3DMHh+/nbeXmouH/yHPrH8ffy5eLi18F/iuXvMgLF9rtlcXprLaf8hrOPueyxkePqfcAuw/dor0PzXeVC8GVaaM4RVlJjhKnd37W2PeSvMOBYkTrbx1Jlw9axtjYg1N6ULjDVnQFSWmhvXFew/1n1Vt7dMQ9y8IbhD/VtQnBkkvIMVGkRaMQULadBHv6by1LdbqDGgf4cQ3rqpDyGN3bysJaipNnd7LMmCkmxz34WSbLOfviTLnCFQVlB7n39s9cOz4eEHQe2Pu8XX3seZz7m6m3+c3TyPPXZ1PxZGDMMMC2UFJ6zOWHfLN/+A14WIoozG1+ZeOxjRw+/Yvbu32arg7mN2Ibh5m8eOP+4fdWx2jk9Y4//gV5WbAacuaFhcjgUI33CNbxBxYgoWclJLd2YzdeZ6isqraB/iw3sT+zbtWheOVl1V+8c8/1jwqCg21zYoLzKfsz6uvZXmmrtONrTOQWO5epi3yqOn38LgHVK7Y2XSsfvA9rUtKn7HZjm4uJ55fSIip0HBQn7XrsNF3PrRWtLzSvH3dOP1Cb0Z0lnrSNRTWWZ2BeSnmV0x+elwpPZx3RTaqgpzNsOpwoOLm9nFUnerW5XRK9AcexCadCxI+IQ0z/cnItJIChZySnklFdz133WsTs3DxQLTxnZn4qAOji6r9aqpNgNGVbl5X/fY3dsMD+4+6ioQkVarsX+/NZKqDQvx9eC/t/Xnmj6x1Bgwbc4Wnvj6NyqrTzG6Xxrm4mqGCO8gc6ZDYKzZ+hAQY3ZbKFSISBugYNHGebq58s9revDIqK5YLPDflWlM/mANBUcrHV2aiIi0QgoWgsVi4c4hibx9Yx98PFz5eXcO49/4he2ZZzmbQkRE2hwFC7Ea0T2Kz+8aSEygF3tzSrjyjV/4ct0BR5clIiKtiIKF2OgeE8h39w1mcKcwyiprePDzTTzy1WbKKu24IJOIiDgtBQupJ8TXgw8n9+dPl3TGYoHPVu/n6jd/JS23xNGliYhIC6dgIQ1ydbFw/yWd+PiW/oT4erAlo5Axr/3Mj1vOYsEoERFxegoW8rsGdwpn7n0X0ic+mKKyKu747zpmfL9NU1JFRKRBChZyStGB3sy643xuuzABgLeX7WXCf1ZxuLDMwZWJiEhLo2AhjeLu6sLjY5J568be+Hu6sTo1j8v/tZzF27McXZqIiLQgChZyWkaeE82cey+kW3QAOcUVTP5wDU9+85tmjYiICKBgIWcgIcyX2fcM4pYLzK6Rj1ekMfa1n9mSUeDgykRExNEULOSMeLm78uTYZD6+pT/h/p7syirmyjd+4Z1le6ipadZ97UREpAVRsJCzclHncH544CIuTY6kstrgue+3c9P7q8gs0MBOEZG2SMFCzlqIrwfv3NSHGVedi7e7K7/szuWyV5bxfcohR5cmIiLN7LSCxYwZM+jXrx/+/v5ERERw5ZVXsmPHjqaqTVoRi8XC9f3bM/e+C+kRG0jB0Urumbmev36+iaIy7ZQqItJWnFawWLp0KVOmTGHlypUsWLCAqqoqRowYQUmJlnoWU8dwP768exBThiViscDn6w4w8pXl/Lonx9GliYhIM7AYhnHGI+2ys7OJiIhg6dKlXHTRRY16TWFhIYGBgRQUFBAQEHCmHy2twKq9ufzli03szzsKwKRBHXh4ZFe8PVwdXJmIiJyuxv79PqsxFgUF5vTCkJCQk55TXl5OYWGhzU3ahgEdQ5l3/0XcMKA9AB/+msrofy1nXVqegysTEZGmcsYtFoZhMG7cOI4cOcLy5ctPet706dN56qmn6h1Xi0XbsnRnNg9/sZnMwjJcLHD7RR350yWd8XJX64WISGvQ2BaLMw4WU6ZMYe7cufz888/Exsae9Lzy8nLKy8ttCouLi1OwaIMKjlby9Ldb+XL9AQA6Rfjx0rW9ODc20MGViYjIqTRpsLj33nv5+uuvWbZsGQkJCU1SmDivBVsP88hXKeQUl+PqYmHKsCSmDkvCw02zn0VEWqomGWNhGAZTp07lq6++YtGiRacdKkQALk2O5Mc/XcTlPaKprjH410+7GPXqMpbvynZ0aSIicpZOq8Xinnvu4dNPP+Wbb76hS5cu1uOBgYF4e3s36j3UYiHH+25zBtO+2UJuSQUAI7tH8fiYbsQG+zi4MhEROV6TdIVYLJYGj3/wwQdMmjTJroVJ21FwtJJXFu7k4xVpVNcYeLq5cM/QJO4c0lGDO0VEWogmH7x5phQs5GR2ZBYxbc5vrNxrTkeNDfbmyTHJXJocedJQKyIizUPBQlolwzCYm3KIv8/dxqHajcwu6hzOtLHJJIb7Obg6EZG2S8FCWrXSiireWLyb/yzbR0V1De6uFiZfkMDUi5MI8HJ3dHkiIm2OgoU4hdScEp7+biuLtmcBEOrrwZ9HdOaP/drj6qLuERGR5qJgIU5l8fYsnp27lT3Z5oZ3XaP8eWJMMhckhTm4MhGRtkHBQpxOZXUNM1em8fLCXRQcNbdiv6RbJI9d3o2EMF8HVyci4twULMRp5ZdW8MrCXfx3pTk91d3VwsSBHbh3eCcCvTX+QkSkKShYiNPbnVXE3+duY/EOc8XOYB93/nxpZ67v3x43Vy0PLiJiTwoW0mYs2ZHFs3O3sTurGICkCD8eG92NoV3Ctf6FiIidKFhIm1JVXcOnq9N5ecFOjpSa4y8Gdwrjscu70TVKP2ciImdLwULapIKjlfx78W4++CWViuoaXCxwXb84/nRpZyL8vRxdnohIq6VgIW1aem4pL8zfztyUQwD4erhyz7Akbr0wQfuPiIicAQULEWBtah7PfLeVTQcKAIgJ9OKhkV0Z2zNGC2yJiJwGBQuRWjU1Bt9uzuCFedvJqN1/pFOEH/cN78Toc6MVMEREGkHBQuQEZZXVvPfzPt5euofCsipAAUNEpLEULEROorCskg9/SeXd5XutASOpNmBcroAhItIgBQuRU1DAEBFpPAULkUY6WcCYMiyRsT1itIqniAgKFiKnraGA0T7Eh7uHJnJV73Z4ummaqoi0XQoWImeosKyS/65I472f95FXUgFAVIAXd1zUkev7t8fbQwFDRNoeBQuRs1RaUcWnq9L5z/K9HC4sByDU14NbBydw0/nx+HtpJ1URaTsULETspLyqmi/WHeCtpXvYn3cUgAAvNyYN6sCkCxII8fVwcIUiIk1PwULEzqqqa5izKYM3Fu9mT3YJAN7urlzXL45bL0wgLsTHwRWKiDQdBQuRJlJTYzB/Syb/XrKb3w4WAuDqYmFMj2juvCiR5Bj9XIuI81GwEGlihmHwy+5c3lq6h59351iPD+kczl1DEjm/YwgWi9bCEBHnoGAh0ox+O1jAW0v38H3KIWpq/4/qGRvIXUMSGdE9SottiUirp2Ah4gBpuSX8Z/lePl97gPKqGgDiQ3245YIErukTi6+nm4MrFBE5MwoWIg6UU1zOR7+m8vGKNAqOVgLmTJLr+7dn4qAOxAR5O7hCEZHTo2Ah0gKUVlTx5boDvP9LKvtyzJkkri4WRp8bza0XJtArLsixBYqINJKChUgLUlNjsGh7Fu/9vI8Ve3Otx/vEB3PrhQmMSI7UniQi0qIpWIi0UFsyCnj/51TmbDpIZbX5v1+7IG+u7x/Htf3iiPD3cnCFIiL1KViItHBZhWX8d2Uan6xM40ipOQ7DzcXCZd2jmDCgPQMTQzVdVURaDAULkVairLKa71MOMXNVOuvSjliPdwzz5YYB7bmmTyxBPlo2XEQcS8FCpBXadqiQmavSmL3+ICUV1QB4uLkwpkc0EwbE07t9kFoxRMQhFCxEWrHi8irmbMzgk5VpbD1UaD3eNcqfCQPaM+68dgRod1URaUYKFiJOwDAMNu7P55OV6Xy3OcO66Ja3uyvjesVww4D29IgNcmyRItImKFiIOJmC0kq+2nCAmavS2Z1VbD1+TrsAJgyI54qeMVrZU0SajIKFiJMyDIM1qUeYuSqNeSmZVFSbrRh+nm6M6xXDhAHx2mFVROxOwUKkDcgrqeDLdQf4dHW6dWVPgN7tg5gwIJ7Le0Tj5e7qwApFxFkoWIi0ITU1Biv35jJzVTo/bMmkqnaL1UBvd67pE8sNA9qTGO7n4CpFpDVTsBBpo7KKyvh87QE+XZXOwfyj1uMDO4Yy4fz2jEiOwsNNy4eLyOlRsBBp46prDJbtzGbmqjQWbc+ithGDMD9Pru7djj/0jSUpwt+xRYpIq6FgISJWB/OP8r/V6cxas5+sonLr8V5xQfyhbyxjesQQ6K11MUTk5BQsRKSeyuoaFm3P4vO1B1i8I4vq2mYMTzcXLusexR/6xjIoMQxXF63uKSK2FCxE5HdlF5XzzcaDfL72ADsOF1mPxwR6cXWfWMaf146OGvApIrUULESkUQzDIOVgAZ+vPcA3Gw9SWFZlfe6cdgGM7RHDmJ4xtAvydmCVIuJoChYictrKKqtZuO0wX6w7wM+7cqzTVgH6xAcztkc0o3tEE+Hv5cAqRcQRFCxE5KzklVQw/7dM5mw6yKp9edT9pnCxwMDEUMb2iGHkOVHa0l2kjVCwEBG7OVxYxtzNh/h2cwYb0vOtxz1cXRjeLYKre8cypEs47q5aH0PEWSlYiEiT2J9XyrebM5izMYPtmccGfYb5eTCuVzuu7h2rvUpEnJCChYg0ua0ZhXy53hz0mVNcYT3eLTqAa/rEMq5XDGF+ng6sUETsRcFCRJpNZXUNy3Zm8+X6AyzcmmXdcdXNxcKQzuGM6RnNJd0i8ffSIlwirZWChYg4RH5pBd9uyuCL9QfZtD/fetzDzYUhncO5/NxohneLUMgQaWUULETE4XZnFTFn0yG+25zB3uxj27p7uLkwtHM4l/eIZni3SPw83RxYpYg0hoKFiLQYhmGw43ARczcfYu7mQ+zNORYyPN1cGNolnFHnRHNxtwgC1JIh0iIpWIhIi2QYBtsza0NGyiH2HRcy3F0tXJAUxqhzorikWyShGvgp0mIoWIhIi2cYBlsPFTIvJZN5vx1iz3HdJS4WGJAQyqhzoxiRHEVUoFb7FHEkBQsRaXV2ZxUx/7dM5v2WyZaMQpvnercP4rLuUYzoHkVCmK+DKhRpuxQsRKRV259XyvzfMpm/JZN1aUdsnusc6ceI5ChGdI/k3HaBWCza5l2kqSlYiIjTOFxYxo9bMvlx62FW7Mm12RwtOtCLS5MjGZEcxYCOIVpWXKSJKFiIiFMqOFrJkh1Z/LAlkyU7simtqLY+F+DlxrCuEQzvFsmQTuEE+miGiYi9KFiIiNMrq6zm1z05/LjlMAu2Hia35Niy4q4uFvp1COaSbpFc3DWCjuF+DqxUpPVTsBCRNqW6xmB9+hEWbjvMom1Z7Moqtnm+Y5gvF9e2ZvTtEKwuE5HTpGAhIm1aWm4Ji7Zn8dO2LFbty6Wy+tivOn8vNy5MCmNol3CGdI7QVFaRRlCwEBGpVVRWyfJdOSzcdpglO7LJO67LBKBrlD9Du0QwtEs4feLVmiHSEAULEZEGVNcYbD6Qz5Id2SzZmc3mA/kc/1vQ39ONC5LCGNIlnKFdwokO9HZcsSItiIKFiEgj5BaXs3xXDkt3ZrN0Z/3WjC6R/rVdJuH07RCCh5taM6RtUrAQETlNNTUGKQcLalszsti437Y1w9fDlUHWsRnhxAb7OK5YkWamYCEicpaOlFSwfHcOS3ZksWxnNjnFtq0ZSRF+DO0czpAu4fTrEIKXu6uDKhVpegoWIiJ2VFNjsCWjkCU7sli6M5v16Uc4bgFQvN1dGZgYypDOZmtGB+1nIk5GwUJEpAkVlFayfHc2S3eYYzOyisptno8P9bG2ZpzfMRQfDzcHVSpiH00WLJYtW8Y///lP1q1bx6FDh5g9ezZXXnml3QsTEWktDMNge2YRS3Zks3RnFmtTj9jsZ+Lh6kLfDsFc1DmcizqF0y3aXxunSavT2L/fpx2hS0pK6NmzJ5MnT+bqq68+qyJFRJyBxWKhW3QA3aIDuHtoIkVllazYk8uSnWaLxsH8o/y6J5df9+Ty/LzthPt7MrhTGEM6h3NhUhihfp6O/hZE7OasukIsFotaLEREfodhGOzNKWHZzmyW7cxm5d48jlYe2zjNYoFzYgK5ICmMgYmh9I0PxtdT3SbS8jRZi8XpKi8vp7z8WN9jYWFhU3+kiEiLYbFYSAz3IzHcj8kXJFBeVc3a1CMsq103Y3tmESkHC0g5WMBbS/fg5mKhR2wgAxNDOb9jKH3jQ/D20GwTaT2avMVi+vTpPPXUU/WOq8VCRASyCstYviuHFXtzWbEnl4P5R22ed3e10DM2yBo0ercPVtAQh2iWWSGNCRYNtVjExcUpWIiINGB/Xikr9uaycm8uK/fkklFQZvO8u6uFc9sFMqBjKAMSQujbIQQ/dZ1IM2gxXSGenp54empgkohIY8SF+BAX4sO1feMwDIP0vFJW1rZmrNqXx6GCMtan57M+PZ83l+zB1cXCOTEBDOgYSv8OIfRLCCHQ293R34a0YYq5IiItlMViIT7Ul/hQX67r1x7DMNifd5SV+3JZtTePVftyOXDkKJsOFLDpQAHvLNuLxWLub9K3QzB940Po2yGYdkHemt4qzea0g0VxcTG7d++2fr1v3z42btxISEgI7du3t2txIiJyjMVioX2oD+1DzRYNgIP5R1ltDRp57MspYXtmEdszi/hkZToA0YFe9IkPpl8HM2h0jQrA1UVBQ5rGaY+xWLJkCcOGDat3fOLEiXz44YenfL2mm4qINJ2sojLWpR5hbdoR1qbmsSWj0GaxLgA/TzcGJIQwKCmMC5JC6RKpBbvk1LSkt4iIUFpRxcb9+aytDRvr045QXF5lc06YnwcDE8O4IDGUC5LCiAvRrq1Sn4KFiIjUU11jsO1QIb/szuGXPbms2We7YBdAXIg3FySG0a9DCL3jg+kQ6qMWDVGwEBGRUyuvqmZDej6/1gaNjfvzqT6h6yTE14Pe7YM4r30wvdsH0zMuUJuqtUEKFiIictqKy6tYvc+c3rou7Qi/HSykorrG5hxXFwtdo/zp3T6YPvHBmnnSRihYiIjIWSuvqmZLRiHr046wIT2f9elHOHTCol0AUQFe9OkQTN94c5prt2h/3FxdHFCxNBUFCxERaRKHCo6yPi2fdWlHWJd+hC0HC+rNPPHxcOW89kH0iQ+hb3ww57UPwt9LC3e1ZgoWIiLSLI5WVLNxfz7r0vJYm3aEdWlHKCqznXlSt3BXXddJn/YhxIWo+6Q1UbAQERGHqKkx2JlVxNpUM2SsTctjf97ReueF+XnSJz6IvvEh9I4PIjk6UBustWAKFiIi0mJkFZaxPr0uaBzht4MFVFbb/vlxdbHQKcKPHrGB9IgNokdsIF2i/PF0U9hoCRQsRESkxSqrrOa3gwXWrpMN6fnkFJfXO8/d1ULXqADOjQ2kR7tAzo0NpHOkP+4aGNrsFCxERKTVMAyDw4XlbDqQT8qBAjYfLCDlQD5HSivrnevh5kJydAA9YgM5p10gPWIDSQr30yyUJqZgISIirZphGBw4cpTNBwrYfDCfzfsL+C2joN7AUAAvdxe6xwRybrvaW2wgieF+2mzNjhQsRETE6dTUGKTnlVpbNFIOFvDbwcJ6+5+AOeU1OdrsRjm3tmUjIUxh40wpWIiISJtQU2OwL7fE7EI5UMBvB82WjdKK6nrn+ni40j0mgHPaBZIcHUD3mEA6RfppzEYjKFiIiEibVV1jsC+nmJSDx4WNg4X1NlwD8HB1oXOUH92jA+neLoDuMQF0jQrA11P7oRxPwUJEROQ41TUGe7OL2XyggC0ZhWzJKGDrocIGx2xYLNAxzJdeccH0igukZ1wQXaMC8HBruy0bChYiIiKnYBgG+/OOsiXjWNjYklFIVlH9qa8ebi50jwmgV1yQ9dY+pO1sKa9gISIicoayi8pJOZjPxv0FbNyfz6b9+RQcrT/1NcDLjU6R/nSK8CMpwo/ECD86RfgRE+iNi5MNElWwEBERsRPDMEjNLWXT/nw21t62ZtTfUr6Ot7sriRG+dIrwJynCj45hvnQM9yM+1Acv99a5kqiChYiISBMqr6pmd1Yxu7OK2ZNVzO5s8/G+nJJ6y5XXcbFAu2BvOob50THcl8TwY/cR/p4tultFwUJERMQBKqtrSM8rtQkde3JK2JtVTFED623UCfByo2t0AF2j/OkaFUCXKH+6RPnj10JmpyhYiIiItCCGYZBdXM7e7JLaWzF7c8z7/UeOUl3T8J/juBBvukQG0C3a7FaJD/UlIdSXQB/3Zq1fwUJERKSVKK+qZk9WCdszC9mRWcS2zCJ2ZBZyuLD+7JQ6QT7udAj1JSHMl/hQn9r7pgsdChYiIiKt3JGSCrbXhowdh4vYk11CWm7J7wYOgIV/voikCH+71tLYv98to+NGRERE6gn29WBgYigDE0NtjpdWVJGWW0pqTgn7cktIyyk173NLyC4qJzbYx0EVK1iIiIi0Oj4ebnSLDqBbdP2Wg6MV1Q6d0tp21yYVERFxQt4ejl0nQ8FCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7KbZt003DAOAwsLC5v5oEREROUN1f7fr/o6fTLMHi6KiIgDi4uKa+6NFRETkLBUVFREYGHjS5y3GqaKHndXU1JCRkYG/vz8Wi8Vu71tYWEhcXBz79+8nICDAbu8rDdP1bl663s1L17t56Xo3rzO93oZhUFRURExMDC4uJx9J0ewtFi4uLsTGxjbZ+wcEBOgHsxnpejcvXe/mpevdvHS9m9eZXO/fa6moo8GbIiIiYjcKFiIiImI3ThMsPD09mTZtGp6eno4upU3Q9W5eut7NS9e7eel6N6+mvt7NPnhTREREnJfTtFiIiIiI4ylYiIiIiN0oWIiIiIjdKFiIiIiI3ThNsPj3v/9NQkICXl5e9OnTh+XLlzu6JKewbNkyxo4dS0xMDBaLha+//trmecMwmD59OjExMXh7ezN06FC2bNnimGJbuRkzZtCvXz/8/f2JiIjgyiuvZMeOHTbn6Hrbz5tvvkmPHj2siwQNHDiQefPmWZ/XtW5aM2bMwGKx8MADD1iP6Zrbz/Tp07FYLDa3qKgo6/NNea2dIlj873//44EHHuCxxx5jw4YNDB48mFGjRpGenu7o0lq9kpISevbsyeuvv97g8//4xz946aWXeP3111mzZg1RUVFceuml1j1hpPGWLl3KlClTWLlyJQsWLKCqqooRI0ZQUlJiPUfX235iY2N5/vnnWbt2LWvXruXiiy9m3Lhx1l+uutZNZ82aNbzzzjv06NHD5riuuX11796dQ4cOWW8pKSnW55r0WhtOoH///sZdd91lc6xr167G3/72NwdV5JwAY/bs2dava2pqjKioKOP555+3HisrKzMCAwONt956ywEVOpesrCwDMJYuXWoYhq53cwgODjbeffddXesmVFRUZHTq1MlYsGCBMWTIEOP+++83DEM/3/Y2bdo0o2fPng0+19TXutW3WFRUVLBu3TpGjBhhc3zEiBH8+uuvDqqqbdi3bx+ZmZk2197T05MhQ4bo2ttBQUEBACEhIYCud1Oqrq5m1qxZlJSUMHDgQF3rJjRlyhQuv/xyLrnkEpvjuub2t2vXLmJiYkhISOCPf/wje/fuBZr+Wjf7JmT2lpOTQ3V1NZGRkTbHIyMjyczMdFBVbUPd9W3o2qelpTmiJKdhGAZ//vOfufDCCznnnHMAXe+mkJKSwsCBAykrK8PPz4/Zs2eTnJxs/eWqa21fs2bNYv369axZs6bec/r5tq8BAwbw8ccf07lzZw4fPsyzzz7LoEGD2LJlS5Nf61YfLOqcuAW7YRh23ZZdTk7X3v6mTp3K5s2b+fnnn+s9p+ttP126dGHjxo3k5+fz5ZdfMnHiRJYuXWp9Xtfafvbv38/999/Pjz/+iJeX10nP0zW3j1GjRlkfn3vuuQwcOJDExEQ++ugjzj//fKDprnWr7woJCwvD1dW1XutEVlZWvTQm9lU3wljX3r7uvfde5syZw+LFi4mNjbUe1/W2Pw8PD5KSkujbty8zZsygZ8+evPrqq7rWTWDdunVkZWXRp08f3NzccHNzY+nSpfzrX//Czc3Nel11zZuGr68v5557Lrt27Wryn+9WHyw8PDzo06cPCxYssDm+YMECBg0a5KCq2oaEhASioqJsrn1FRQVLly7VtT8DhmEwdepUvvrqKxYtWkRCQoLN87reTc8wDMrLy3Wtm8Dw4cNJSUlh48aN1lvfvn2ZMGECGzdupGPHjrrmTai8vJxt27YRHR3d9D/fZz38swWYNWuW4e7ubrz33nvG1q1bjQceeMDw9fU1UlNTHV1aq1dUVGRs2LDB2LBhgwEYL730krFhwwYjLS3NMAzDeP75543AwEDjq6++MlJSUozrr7/eiI6ONgoLCx1ceetz9913G4GBgcaSJUuMQ4cOWW+lpaXWc3S97eeRRx4xli1bZuzbt8/YvHmz8eijjxouLi7Gjz/+aBiGrnVzOH5WiGHomtvTgw8+aCxZssTYu3evsXLlSmPMmDGGv7+/9e9iU15rpwgWhmEYb7zxhhEfH294eHgYvXv3tk7Rk7OzePFiA6h3mzhxomEY5rSladOmGVFRUYanp6dx0UUXGSkpKY4tupVq6DoDxgcffGA9R9fbfm655Rbr74zw8HBj+PDh1lBhGLrWzeHEYKFrbj/XXXedER0dbbi7uxsxMTHGVVddZWzZssX6fFNea22bLiIiInbT6sdYiIiISMuhYCEiIiJ2o2AhIiIidqNgISIiInajYCEiIiJ2o2AhIiIidqNgISIiInajYCEizc5isfD11187ugwRaQIKFiJtzKRJk7BYLPVuI0eOdHRpIuIEnGbbdBFpvJEjR/LBBx/YHPP09HRQNSLiTNRiIdIGeXp6EhUVZXMLDg4GzG6KN998k1GjRuHt7U1CQgKff/65zetTUlK4+OKL8fb2JjQ0lDvuuIPi4mKbc95//326d++Op6cn0dHRTJ061eb5nJwcxo8fj4+PD506dWLOnDnW544cOcKECRMIDw/H29ubTp061QtCItIyKViISD1PPPEEV199NZs2beLGG2/k+uuvZ9u2bQCUlpYycuRIgoODWbNmDZ9//jkLFy60CQ5vvvkmU6ZM4Y477iAlJYU5c+aQlJRk8xlPPfUU1157LZs3b2b06NFMmDCBvLw86+dv3bqVefPmsW3bNt58803CwsKa7wKIyJmzy1ZmItJqTJw40XB1dTV8fX1tbk8//bRhGOYuq3fddZfNawYMGGDcfffdhmEYxjvvvGMEBwcbxcXF1ufnzp1ruLi4GJmZmYZhGEZMTIzx2GOPnbQGwHj88cetXxcXFxsWi8WYN2+eYRiGMXbsWGPy5Mn2+YZFpFlpjIVIGzRs2DDefPNNm2MhISHWxwMHDrR5buDAgWzcuBGAbdu20bNnT3x9fa3PX3DBBdTU1LBjxw4sFgsZGRkMHz78d2vo0aOH9bGvry/+/v5kZWUBcPfdd3P11Vezfv16RowYwZVXXsmgQYPO6HsVkealYCHSBvn6+tbrmjgVi8UCgGEY1scNnePt7d2o93N3d6/32pqaGgBGjRpFWloac+fOZeHChQwfPpwpU6bw4osvnlbNItL8NMZCROpZuXJlva+7du0KQHJyMhs3bqSkpMT6/C+//IKLiwudO3fG39+fDh068NNPP51VDeHh4UyaNIlPPvmEV155hXfeeees3k9EmodaLETaoPLycjIzM22Oubm5WQdIfv755/Tt25cLL7yQmTNnsnr1at577z0AJkyYwLRp05g4cSLTp08nOzube++9l5tuuonIyEgApk+fzl133UVERASjRo2iqKiIX375hXvvvbdR9T355JP06dOH7t27U15eznfffUe3bt3seAVEpKkoWIi0QfPnzyc6OtrmWJcuXdi+fTtgztiYNWsW99xzD1FRUcycOZPk5GQAfHx8+OGHH7j//vvp168fPj4+XH311bz00kvW95o4cSJlZWW8/PLL/OUvfyEsLIxrrrmm0fV5eHjwyCOPkJqaire3N4MHD2bWrFl2+M5FpKlZDMMwHF2EiLQcFouF2bNnc+WVVzq6FBFphTTGQkREROxGwUJERETsRmMsRMSGekdF5GyoxUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROxGwUJERETsRsFCRERE7EbBQkREROzm/wMN/sgqQduB+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), 'transformer_obolo_to_english_bpe_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer, 'transformer_obolo_to_english_bpe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=50257, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(15866, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=torch.load('transformer_obolo_to_english_bpe.pt')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        # print(out)\n",
    "        # print(english_tokenizer.decode(out))\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        # print(next_word)\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # save vram\n",
    "        del tgt_mask \n",
    "        torch.cuda.empty_cache()\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    \n",
    "    return token_transform[TGT_LANGUAGE].decode(tgt_tokens[1:-1])\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 24, 73, 8, 42, 108, 24, 42, 660, 1518, 124, 42, 163, 42, 85, 319, 42, 660, 20, 42, 405, 42, 694, 694, 20, 42, 168, 28, 42, 20, 69, 42, 24, 89, 239, 42, 405, 42, 58, 42, 20, 110, 42, 20, 69, 42, 24, 8207, 5228, 24, 10, 42, 168, 28, 42, 88, 5997, 42, 405, 42, 694, 694, 20, 42, 20, 110, 42, 20, 69, 42, 24, 89, 239, 42, 24, 42, 58, 415, 214, 2] torch.Size([80, 1])\n",
      "[CLS]ire, emi okumugwem ma ̂tap oke me etete anam ebi ijeren me ̀ echi ebi ijipiti. anam geege me etete echi ebi ijeren i ̀kpokwu[SEP]\n"
     ]
    }
   ],
   "source": [
    "src_sentence = \"ire, emi okumugwem mâtap oke me etete anam ebi ijeren mè echi ebi ijipiti. anam geege me etete echi ebi ijeren ìkpokwu\"\n",
    "src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "print(list(src.numpy().flatten()), src.shape)\n",
    "print(token_transform[SRC_LANGUAGE].decode(src.numpy().flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE TRANSLATE ACTUALLY WORK !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])\n",
    "\n",
    "def test_model(m):\n",
    "    preds = []\n",
    "    refs = []\n",
    "    for idx in tqdm(range(len(test['Obolo']))):\n",
    "        ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "        refs.append(en)\n",
    "        pred = translate(m, ob)\n",
    "        preds.append(pred)\n",
    "    print(len(preds), len(refs))\n",
    "    chrf_plusplus = chrf.compute(predictions=preds, references=refs, word_order=2)\n",
    "    other_metrics = metrics.compute(predictions=preds, references=refs)\n",
    "    return (chrf_plusplus, other_metrics)\n",
    "# def test_model(m):\n",
    "#     preds = []\n",
    "#     refs = []\n",
    "#     for idx in tqdm(range(len(test['Obolo']))):\n",
    "#         ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "#         refs.append(ob)\n",
    "#         pred = translate(m, en)\n",
    "#         preds.append(pred)\n",
    "#     print(len(preds), len(refs))\n",
    "#     chrf_plusplus = chrf.compute(predictions=preds, references=refs, word_order=2)\n",
    "#     other_metrics = metrics.compute(predictions=preds, references=refs)\n",
    "#     return (chrf_plusplus, other_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=7150, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(7150, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:29<00:00,  5.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 31.4594364184561, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 33.1183382693422,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.0965839369096732,\n",
       "  'precisions': [0.4439593452564786,\n",
       "   0.17493879692235953,\n",
       "   0.07409034447238465,\n",
       "   0.03506087943978298],\n",
       "  'brevity_penalty': 0.8104037923231848,\n",
       "  'length_ratio': 0.8262942384205826,\n",
       "  'translation_length': 71234,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.40209917560946296,\n",
       "  'rouge2': 0.1688320075056018,\n",
       "  'rougeL': 0.330439312992152,\n",
       "  'rougeLsum': 0.3302889543180393,\n",
       "  'meteor': 0.27499811487427545,\n",
       "  'google_bleu': 0.14902439883938115})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:12<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 34.60890032170223, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 36.45257913325245,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12375037959937117,\n",
       "  'precisions': [0.46202111368595083,\n",
       "   0.19926665823745102,\n",
       "   0.09609018389698269,\n",
       "   0.05197010354603478],\n",
       "  'brevity_penalty': 0.8451120090240163,\n",
       "  'length_ratio': 0.8559547147049612,\n",
       "  'translation_length': 73791,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.42594365363152303,\n",
       "  'rouge2': 0.19672495711620275,\n",
       "  'rougeL': 0.35142566208222015,\n",
       "  'rougeLsum': 0.3515269770697331,\n",
       "  'meteor': 0.2990011024367041,\n",
       "  'google_bleu': 0.16980087851142414})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:15<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 35.8645034031162, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 37.871225550705056,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.1314852977175387,\n",
       "  'precisions': [0.46451269069349144,\n",
       "   0.2040996618124094,\n",
       "   0.10156798167108183,\n",
       "   0.05624395686128672],\n",
       "  'brevity_penalty': 0.8619043144601847,\n",
       "  'length_ratio': 0.8706167569511304,\n",
       "  'translation_length': 75055,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.43278884146234514,\n",
       "  'rouge2': 0.20327690740077292,\n",
       "  'rougeL': 0.35567630273607376,\n",
       "  'rougeLsum': 0.35554910123929573,\n",
       "  'meteor': 0.3055120263009529,\n",
       "  'google_bleu': 0.17569874243778957})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:08<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 36.190355946973, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 38.37663027147303,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12951030123890808,\n",
       "  'precisions': [0.47209337124046086,\n",
       "   0.20605616123436243,\n",
       "   0.10222131111534125,\n",
       "   0.05645210401315389],\n",
       "  'brevity_penalty': 0.8413865042709813,\n",
       "  'length_ratio': 0.8527299933881614,\n",
       "  'translation_length': 73513,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.43998740386245805,\n",
       "  'rouge2': 0.2079964625119528,\n",
       "  'rougeL': 0.3639936206259728,\n",
       "  'rougeLsum': 0.36428226798504276,\n",
       "  'meteor': 0.3073477292188966,\n",
       "  'google_bleu': 0.17534979953009386})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:14<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 35.64635608493907, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 37.75723550215659,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12596321547781203,\n",
       "  'precisions': [0.4652110195356091,\n",
       "   0.19899117979015424,\n",
       "   0.09670749164943535,\n",
       "   0.05313537800351631],\n",
       "  'brevity_penalty': 0.8529268967889252,\n",
       "  'length_ratio': 0.8627521488475681,\n",
       "  'translation_length': 74377,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.43130980811161257,\n",
       "  'rouge2': 0.20000287266562097,\n",
       "  'rougeL': 0.3543503409004035,\n",
       "  'rougeLsum': 0.3545369197114089,\n",
       "  'meteor': 0.3012917120566398,\n",
       "  'google_bleu': 0.17186173367915422})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "for epoch in [10,20,30,40,50]:\n",
    "    model = torch.load(f'checkpoints/transformer_english_to_obolo_bpe_small_{epoch}_epochs.pt').to(DEVICE)\n",
    "    models.append(model)\n",
    "display(models[0])\n",
    "scores = []\n",
    "for mod in models:\n",
    "    score = test_model(mod)\n",
    "    display(score)\n",
    "    scores.append(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'score': 31.4594364184561, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 33.1183382693422,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.0965839369096732,\n",
       "   'precisions': [0.4439593452564786,\n",
       "    0.17493879692235953,\n",
       "    0.07409034447238465,\n",
       "    0.03506087943978298],\n",
       "   'brevity_penalty': 0.8104037923231848,\n",
       "   'length_ratio': 0.8262942384205826,\n",
       "   'translation_length': 71234,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.40209917560946296,\n",
       "   'rouge2': 0.1688320075056018,\n",
       "   'rougeL': 0.330439312992152,\n",
       "   'rougeLsum': 0.3302889543180393,\n",
       "   'meteor': 0.27499811487427545,\n",
       "   'google_bleu': 0.14902439883938115}),\n",
       " ({'score': 34.60890032170223, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 36.45257913325245,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12375037959937117,\n",
       "   'precisions': [0.46202111368595083,\n",
       "    0.19926665823745102,\n",
       "    0.09609018389698269,\n",
       "    0.05197010354603478],\n",
       "   'brevity_penalty': 0.8451120090240163,\n",
       "   'length_ratio': 0.8559547147049612,\n",
       "   'translation_length': 73791,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.42594365363152303,\n",
       "   'rouge2': 0.19672495711620275,\n",
       "   'rougeL': 0.35142566208222015,\n",
       "   'rougeLsum': 0.3515269770697331,\n",
       "   'meteor': 0.2990011024367041,\n",
       "   'google_bleu': 0.16980087851142414}),\n",
       " ({'score': 35.8645034031162, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 37.871225550705056,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.1314852977175387,\n",
       "   'precisions': [0.46451269069349144,\n",
       "    0.2040996618124094,\n",
       "    0.10156798167108183,\n",
       "    0.05624395686128672],\n",
       "   'brevity_penalty': 0.8619043144601847,\n",
       "   'length_ratio': 0.8706167569511304,\n",
       "   'translation_length': 75055,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.43278884146234514,\n",
       "   'rouge2': 0.20327690740077292,\n",
       "   'rougeL': 0.35567630273607376,\n",
       "   'rougeLsum': 0.35554910123929573,\n",
       "   'meteor': 0.3055120263009529,\n",
       "   'google_bleu': 0.17569874243778957}),\n",
       " ({'score': 36.190355946973, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 38.37663027147303,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12951030123890808,\n",
       "   'precisions': [0.47209337124046086,\n",
       "    0.20605616123436243,\n",
       "    0.10222131111534125,\n",
       "    0.05645210401315389],\n",
       "   'brevity_penalty': 0.8413865042709813,\n",
       "   'length_ratio': 0.8527299933881614,\n",
       "   'translation_length': 73513,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.43998740386245805,\n",
       "   'rouge2': 0.2079964625119528,\n",
       "   'rougeL': 0.3639936206259728,\n",
       "   'rougeLsum': 0.36428226798504276,\n",
       "   'meteor': 0.3073477292188966,\n",
       "   'google_bleu': 0.17534979953009386}),\n",
       " ({'score': 35.64635608493907, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 37.75723550215659,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12596321547781203,\n",
       "   'precisions': [0.4652110195356091,\n",
       "    0.19899117979015424,\n",
       "    0.09670749164943535,\n",
       "    0.05313537800351631],\n",
       "   'brevity_penalty': 0.8529268967889252,\n",
       "   'length_ratio': 0.8627521488475681,\n",
       "   'translation_length': 74377,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.43130980811161257,\n",
       "   'rouge2': 0.20000287266562097,\n",
       "   'rougeL': 0.3543503409004035,\n",
       "   'rougeLsum': 0.3545369197114089,\n",
       "   'meteor': 0.3012917120566398,\n",
       "   'google_bleu': 0.17186173367915422})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:42<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 34.774253886934794,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.11017722886419022,\n",
       " 'precisions': [0.386394229803307,\n",
       "  0.15402946273830156,\n",
       "  0.07010792358416555,\n",
       "  0.03531553927340922],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.2377186765638406,\n",
       " 'translation_length': 99546,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.38876618138191454,\n",
       " 'rouge2': 0.15167336303164228,\n",
       " 'rougeL': 0.32818470447982817,\n",
       " 'rougeLsum': 0.3281664178921254,\n",
       " 'meteor': 0.33593630617140496,\n",
       " 'google_bleu': 0.1614613648663828}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:06<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 38.37993393545994,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.14979800723917194,\n",
       " 'precisions': [0.4484263392857143,\n",
       "  0.1950339119439016,\n",
       "  0.10005925574780754,\n",
       "  0.05753943989238107],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1140537381725042,\n",
       " 'translation_length': 89600,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.43388821312249637,\n",
       " 'rouge2': 0.1880674209030742,\n",
       " 'rougeL': 0.36556917629854546,\n",
       " 'rougeLsum': 0.3654439543934844,\n",
       " 'meteor': 0.37230503517222907,\n",
       " 'google_bleu': 0.19485563169449804}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:21<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 38.92617419691285,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.17018996617377927,\n",
       " 'precisions': [0.483790461763866,\n",
       "  0.21497773614443916,\n",
       "  0.11491124417477662,\n",
       "  0.07019763715633554],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0013925671727155,\n",
       " 'translation_length': 80539,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.4500795318755542,\n",
       " 'rouge2': 0.20127863292405612,\n",
       " 'rougeL': 0.37816123135216684,\n",
       " 'rougeLsum': 0.37799380918349657,\n",
       " 'meteor': 0.37445390228135883,\n",
       " 'google_bleu': 0.20451922850481596}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:07<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 40.41674493084158,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.16555905508506247,\n",
       " 'precisions': [0.4631978124613186,\n",
       "  0.20965254993797605,\n",
       "  0.11296280799072292,\n",
       "  0.06848723422634105],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1049398833724993,\n",
       " 'translation_length': 88867,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.4492976833221257,\n",
       " 'rouge2': 0.20482741611037522,\n",
       " 'rougeL': 0.3783352021612897,\n",
       " 'rougeLsum': 0.3782361068174826,\n",
       " 'meteor': 0.38591053665286484,\n",
       " 'google_bleu': 0.20687099470604625}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:28<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 40.721980527557136,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.15932930884219138,\n",
       " 'precisions': [0.44594331878861193,\n",
       "  0.19924870523905844,\n",
       "  0.10826618441534658,\n",
       "  0.06699072653908776],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1512054409588819,\n",
       " 'translation_length': 92588,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.4438558502216844,\n",
       " 'rouge2': 0.20023932342100625,\n",
       " 'rougeL': 0.37049227050340316,\n",
       " 'rougeLsum': 0.37035164579594804,\n",
       " 'meteor': 0.3807886400626061,\n",
       " 'google_bleu': 0.20173534614675015}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# models = []\n",
    "# for epoch in [10,20,30,40,50]:\n",
    "#     model = torch.load(f'checkpoints/transformer_obolo_to_english_combination_{epoch}_epochs.pt').to(DEVICE)\n",
    "#     models.append(model)\n",
    "\n",
    "# scores = []\n",
    "# for mod in models:\n",
    "#     score = test_model(mod)\n",
    "#     display(score)\n",
    "#     scores.append(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3110 3110\n"
     ]
    }
   ],
   "source": [
    "print(len(preds), len(refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 33.04091540787891,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.10531583607718822,\n",
       " 'precisions': [0.39940596433941206,\n",
       "  0.15199285856734504,\n",
       "  0.06464365746494309,\n",
       "  0.0313480889373341],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1160628802618981,\n",
       " 'translation_length': 108411,\n",
       " 'reference_length': 97137,\n",
       " 'rouge1': 0.3765356456692016,\n",
       " 'rouge2': 0.13864376297768582,\n",
       " 'rougeL': 0.31799077304173684,\n",
       " 'rougeLsum': 0.3181688900030759,\n",
       " 'meteor': 0.3184619515531625,\n",
       " 'google_bleu': 0.1572599755737436}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = metrics.compute(predictions=preds, references=refs)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentence translation\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "m = torch.load('transformer_obolo_to_english_bpe.pt').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hear ye now what the lord saith; arise, contend thou before the mountains, and let the hills hear thy voice.\n",
      "hearken ye unto the lord, saith the lord; hear ye from the mountain, and hear your words, which hear your words which hear your words.\n"
     ]
    }
   ],
   "source": [
    "print(test['English'][100])\n",
    "print(translate(m, test['Obolo'][100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the king said unto zerah, what [is] thy father? and he said unto him, behold, i [am] this day: for this day is come to jerusalem, because he hath sent me to day, and said, this is come unto me, and i will give him to my father.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ogwu ubọọn̄ oneniyaka ido siba ibe, “sà gwun̄ nte uwu kwun̄ ìkup me owa?” siba ofọfọọk ibe ke ọmọ òwa me jeruselem okupbe, mije, ìkikeek ibe, usini mgbọ, cherekeyi, ke ebi uwu kè ijeren mêniyaka irek mkpulu nte nte kan̄ inyi ọmọ.\"\n",
    "print(translate(m, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# refs = []\n",
    "# for idx in tqdm(range(300)):\n",
    "#     ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "#     refs.append(en)\n",
    "#     pred = translate(m, ob)\n",
    "#     preds.append(pred)\n",
    "    \n",
    "# scores = metrics.compute(predictions=preds, references=refs)\n",
    "# scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
