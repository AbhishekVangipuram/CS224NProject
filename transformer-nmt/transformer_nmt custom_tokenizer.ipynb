{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from evaluate import load, combine\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer import *\n",
    "from dataset import *\n",
    "\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "# from custom_tokenizers.tokenizerv1 import parse_sentence\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7165\n",
      "50257\n",
      "cuda\n",
      "en ob\n"
     ]
    }
   ],
   "source": [
    "# get data \n",
    "train = load_dataset('csv', data_files='../data/train.csv')['train']\n",
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "VAL_CUTOFF = 500 # random choice for val loss, full test set is 3110, take 500 away for validation only. \n",
    "val = test[:VAL_CUTOFF]\n",
    "test = test[VAL_CUTOFF:]\n",
    "\n",
    "# obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/obolo-bpe-tokenizer.json', padding='left')\n",
    "english_tokenizer = AutoTokenizer.from_pretrained('gpt2', padding='left')\n",
    "\n",
    "# from custom_tokenizers.tokenizerv2 import parse_sentence\n",
    "from custom_tokenizers.dt_tokenizer import parse_sentence\n",
    "# # we construct this vocab by calculating tokens from train data\n",
    "# obolo_vocab_sents = [set(parse_sentence(s)) for s in train['Obolo']]\n",
    "# obolo_vocab = set()\n",
    "# for sent in obolo_vocab_sents:\n",
    "#     obolo_vocab.update(sent)\n",
    "# obolo_vocab = special_tokens + list(obolo_vocab)\n",
    "# obolo_vocab = {token:idx for idx, token in enumerate(obolo_vocab)}\n",
    "\n",
    "# # Serialize data into file:\n",
    "# # json.dump( obolo_vocab, open( \"../custom_tokenizers/custom_obolo_tokenizer_vocab_2.json\", 'w' ) )\n",
    "# json.dump( obolo_vocab, open( \"../custom_tokenizers/custom_obolo_detokenizer_vocab.json\", 'w' ) )\n",
    "\n",
    "\n",
    "# Read data from file:\n",
    "# obolo_vocab = json.load( open( \"../custom_tokenizers/custom_obolo_tokenizer_vocab_2.json\" ) )\n",
    "obolo_vocab = json.load( open( \"../custom_tokenizers/custom_obolo_detokenizer_vocab.json\" ) )\n",
    "\n",
    "\n",
    "print(len(obolo_vocab))\n",
    "print(len(english_tokenizer.vocab))\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "# token_transform[SRC_LANGUAGE] = parse_sentence\n",
    "# token_transform[TGT_LANGUAGE] = english_tokenizer\n",
    "\n",
    "# vocab_transform[SRC_LANGUAGE] = obolo_vocab \n",
    "# vocab_transform[TGT_LANGUAGE] = english_tokenizer.vocab\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'ob'\n",
    "token_transform[SRC_LANGUAGE] = english_tokenizer\n",
    "token_transform[TGT_LANGUAGE] = parse_sentence\n",
    "\n",
    "vocab_transform[SRC_LANGUAGE] = english_tokenizer.vocab \n",
    "vocab_transform[TGT_LANGUAGE] = obolo_vocab\n",
    "\n",
    "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#   vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "init_text_transform(token_transform, SRC_LANGUAGE, TGT_LANGUAGE)\n",
    "\n",
    "# change this due to custom tokenizer\n",
    "# init_text_transform(token_transform)\n",
    "# text_transform[SRC_LANGUAGE] = sequential_transforms((lambda text: [obolo_vocab[token] if token in obolo_vocab else UNK_IDX for token in token_transform[SRC_LANGUAGE](text)]), # input to tokens to ids\n",
    "#                                                      tensor_transform)                                                                                                          # add BOS/EOS and create tensor\n",
    "\n",
    "# text_transform[TGT_LANGUAGE] = sequential_transforms((lambda text: token_transform[TGT_LANGUAGE](text).get('input_ids')),\n",
    "#                                                      tensor_transform)    \n",
    "\n",
    "text_transform[TGT_LANGUAGE] = sequential_transforms((lambda text: [obolo_vocab[token] if token in obolo_vocab else UNK_IDX for token in token_transform[TGT_LANGUAGE](text)]), # input to tokens to ids\n",
    "                                                     tensor_transform)                                                                                                          # add BOS/EOS and create tensor\n",
    "\n",
    "text_transform[SRC_LANGUAGE] = sequential_transforms((lambda text: token_transform[SRC_LANGUAGE](text).get('input_ids')),\n",
    "                                                     tensor_transform)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eya orọ, nnenikana isi lek ogwukaan̄-ene awaji, mè ito ito inyi, mè iriaak uriaak, mè ibeek mbeek, mè ijin otu, mè itap ofọnti ufieejit, mè ifuun̄ lek me ntọn̄.\n",
      "['e', 'ya', 'o', 'rọ', ',', 'n', 'neni', 'kana', 'i', 'si', 'lek', 'ogwukaan̄', '-', 'e', 'ne', 'awaji', ',', 'mè', 'i', 'to', 'i', 'to', 'i', 'nyi', ',', 'mè', 'i', 'riaak', 'uriaak', ',', 'mè', 'i', 'beek', 'm', 'beek', ',', 'mè', 'i', 'jin', 'o', 'tu', ',', 'mè', 'i', 'tap', 'ofọnti', 'ufieejit', ',', 'mè', 'i', 'fuun̄', 'lek', 'me', 'n', 'tọn̄', '.']\n",
      "tensor([   1, 3663, 4948, 2148, 2510, 2491, 6404, 4761, 6466, 1347, 5593, 5110,\n",
      "        5583, 2024, 3663, 1519, 3486, 2491, 3865, 1347, 1128, 1347, 1128, 1347,\n",
      "         443, 2491, 3865, 1347, 5579,  136, 2491, 3865, 1347, 3847, 4775, 3847,\n",
      "        2491, 3865, 1347, 3084, 2148, 1164, 2491, 3865, 1347, 6278, 5203, 6492,\n",
      "        2491, 3865, 1347,  278, 5110, 3449, 6404, 2887, 6770,    2])\n",
      "True\n",
      "and i set my face unto the lord god, to seek by prayer and supplications, with fasting, and sackcloth, and ashes:\n",
      "tensor([    1,   392,  1312,   900,   616,  1986, 12722,   262, 15876,  5770,\n",
      "           11,   284,  5380,   416, 11443,   290,   802,   677,   602,    11,\n",
      "          351, 24845,    11,   290, 23704, 44905,    11,   290, 29914,    25,\n",
      "            2])\n"
     ]
    }
   ],
   "source": [
    "ob_sent, en_sent = train['Obolo'][0], train['English'][0]\n",
    "print(ob_sent)\n",
    "print(parse_sentence(ob_sent))\n",
    "print(text_transform[SRC_LANGUAGE](ob_sent))\n",
    "print([obolo_vocab[token] for token in token_transform[SRC_LANGUAGE](ob_sent)] == list(text_transform[SRC_LANGUAGE](ob_sent))[1:-1])\n",
    "print(en_sent)\n",
    "print(text_transform[TGT_LANGUAGE](en_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# SRC_VOCAB_SIZE = len(obolo_vocab)\n",
    "# print(SRC_VOCAB_SIZE)\n",
    "# TGT_VOCAB_SIZE = english_tokenizer.vocab_size\n",
    "SRC_VOCAB_SIZE = english_tokenizer.vocab_size\n",
    "print(SRC_VOCAB_SIZE)\n",
    "TGT_VOCAB_SIZE = len(obolo_vocab)\n",
    "# ORIGINAL TRANSFORMER CONFIGURATION\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# TWEAKS ARE BAD, JUST USE DEFAULT CONFIG\n",
    "# EMB_SIZE = 512\n",
    "# NHEAD = 16\n",
    "# FFN_HID_DIM = 512\n",
    "# BATCH_SIZE = 64\n",
    "# NUM_ENCODER_LAYERS = 6\n",
    "# NUM_DECODER_LAYERS = 6\n",
    "\n",
    "# train_dataloader = generate_dataloader(train['Obolo'], train['English'], BATCH_SIZE)\n",
    "# val_dataloader = generate_dataloader(val['Obolo'], val['English'], BATCH_SIZE)\n",
    "# test_dataloader = generate_dataloader(test['Obolo'], test['English'], BATCH_SIZE)\n",
    "train_dataloader = generate_dataloader(train['English'], train['Obolo'], BATCH_SIZE)\n",
    "val_dataloader = generate_dataloader(val['English'], val['Obolo'], BATCH_SIZE)\n",
    "test_dataloader = generate_dataloader(test['English'], test['Obolo'], BATCH_SIZE)\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "# optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=7165, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(7165, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.98)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-09\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transformer)\n",
    "display(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 438/438 [01:39<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.373, Val loss: 3.486, Epoch time = 112.945s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 3.315, Val loss: 3.061, Epoch time = 111.190s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 2.978, Val loss: 2.794, Epoch time = 112.308s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 2.743, Val loss: 2.621, Epoch time = 111.328s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 2.560, Val loss: 2.488, Epoch time = 111.719s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 2.411, Val loss: 2.387, Epoch time = 111.201s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 2.288, Val loss: 2.309, Epoch time = 110.708s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 2.182, Val loss: 2.244, Epoch time = 110.113s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 2.091, Val loss: 2.190, Epoch time = 110.604s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 2.009, Val loss: 2.156, Epoch time = 110.295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 1.936, Val loss: 2.125, Epoch time = 110.348s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 1.868, Val loss: 2.098, Epoch time = 110.555s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 1.808, Val loss: 2.070, Epoch time = 110.665s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 1.752, Val loss: 2.052, Epoch time = 110.562s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 1.698, Val loss: 2.042, Epoch time = 110.345s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.652, Val loss: 2.024, Epoch time = 110.304s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 1.604, Val loss: 2.016, Epoch time = 110.011s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 1.562, Val loss: 1.995, Epoch time = 110.551s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 1.522, Val loss: 1.996, Epoch time = 110.461s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 1.482, Val loss: 1.997, Epoch time = 110.263s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 1.444, Val loss: 2.011, Epoch time = 110.325s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 1.409, Val loss: 2.024, Epoch time = 110.533s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 1.375, Val loss: 2.019, Epoch time = 110.888s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 1.342, Val loss: 2.015, Epoch time = 110.503s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 1.308, Val loss: 2.012, Epoch time = 111.656s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 1.277, Val loss: 2.009, Epoch time = 111.542s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 1.247, Val loss: 2.021, Epoch time = 110.298s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 1.217, Val loss: 2.028, Epoch time = 111.084s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 1.190, Val loss: 2.029, Epoch time = 110.172s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 1.163, Val loss: 2.044, Epoch time = 110.358s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 1.135, Val loss: 2.062, Epoch time = 110.845s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 1.110, Val loss: 2.064, Epoch time = 110.354s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 1.087, Val loss: 2.077, Epoch time = 110.353s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 1.062, Val loss: 2.090, Epoch time = 110.022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 1.039, Val loss: 2.103, Epoch time = 110.180s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 1.017, Val loss: 2.118, Epoch time = 110.455s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 0.994, Val loss: 2.120, Epoch time = 110.172s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 0.974, Val loss: 2.146, Epoch time = 110.157s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 0.954, Val loss: 2.151, Epoch time = 110.203s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 0.933, Val loss: 2.167, Epoch time = 110.642s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 0.914, Val loss: 2.189, Epoch time = 110.146s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 0.893, Val loss: 2.199, Epoch time = 110.371s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 0.875, Val loss: 2.224, Epoch time = 110.657s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 0.856, Val loss: 2.232, Epoch time = 111.088s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 0.840, Val loss: 2.254, Epoch time = 111.334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 0.822, Val loss: 2.268, Epoch time = 111.278s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:38<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 0.805, Val loss: 2.282, Epoch time = 111.295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 0.789, Val loss: 2.286, Epoch time = 111.069s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 0.772, Val loss: 2.312, Epoch time = 111.002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [01:37<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.759, Val loss: 2.321, Epoch time = 111.156s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# NUM_EPOCHS = 10\n",
    "NUM_EPOCHS = 50 \n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(transformer, f'checkpoints/transformer_english_to_obolo_custom_{epoch}_epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), 'transformer_obolo_to_english_custom_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer, 'transformer_obolo_to_english_custom.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=50257, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(6864, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=torch.load('transformer_obolo_to_english_custom.pt')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        # print(out)\n",
    "        # print(english_tokenizer.decode(out))\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        # print(next_word)\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # save vram\n",
    "        del tgt_mask\n",
    "        torch.cuda.empty_cache()\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# # actual function to translate input sentence into target language\n",
    "# def translate(model: torch.nn.Module, src_sentence: str):\n",
    "#     model.eval()\n",
    "#     src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "#     num_tokens = src.shape[0]\n",
    "#     src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "#     tgt_tokens = greedy_decode(\n",
    "#         model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    \n",
    "#     return token_transform[TGT_LANGUAGE].decode(tgt_tokens[1:-1])\n",
    "#     return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\")\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "from custom_tokenizers.detokenizer import detokenize\n",
    "reverse_vocab = {}\n",
    "for k, v in vocab_transform[TGT_LANGUAGE].items():\n",
    "    reverse_vocab[v]=k\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    \n",
    "    # return token_transform[TGT_LANGUAGE].decode(tgt_tokens[1:-1])\n",
    "    token_list = [reverse_vocab[id] for id in list(tgt_tokens[1:-1].cpu().numpy())]\n",
    "    return detokenize(token_list)\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['korajin', 'ukọ', 'mêkana']\n",
      "korajin ukọ mêkana\n",
      "7165\n"
     ]
    }
   ],
   "source": [
    "from custom_tokenizers.detokenizer import detokenize\n",
    "tgt_tokens = [1, 400, 4003, 5678, 2]\n",
    "reverse_vocab = {}\n",
    "for k, v in vocab_transform[TGT_LANGUAGE].items():\n",
    "    reverse_vocab[v]=k\n",
    "token_list = [reverse_vocab[v] for v in tgt_tokens[1:-1]]\n",
    "print(token_list)\n",
    "print(detokenize(token_list))\n",
    "print(len(reverse_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_sentence = \"ire, emi okumugwem mâtap oke me etete anam ebi ijeren mè echi ebi ijipiti. anam geege me etete echi ebi ijeren ìkpokwu\"\n",
    "# src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "# print(list(src.numpy().flatten()), src.shape)\n",
    "# print(token_transform[SRC_LANGUAGE].decode(src.numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mgbọ yaage îmun̄be ife chi egwookbe, ibebene ikaan̄ ulọk me lek kiban̄, mè iria osat isi lek kiban̄ me kalidia.\n",
      "and it came to pass, when they saw that they had seen, that they sent to the sea, and sent them to the chaldeans, and sent to the chaldeans.\n",
      "and as soon as she saw them with her eyes, she doted upon them, and sent messengers unto them into chaldea.\n"
     ]
    }
   ],
   "source": [
    "ob, en = test['Obolo'][100], test['English'][100]\n",
    "print(ob)\n",
    "print(translate(m, ob))\n",
    "print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the king said, and where [is] thy master’s son? and ziba said unto the king, behold, he abideth at jerusalem: for he said, to day shall the house of israel restore me the kingdom of my father.\n",
      "and the king said unto the woman, how [is] this thy son, that he may be done unto this house of israel? and he said, nay; for the son of man, i will surely rend the kingdom from the kingdom of israel.\n",
      "which i commanded your fathers in the day [that] i brought them forth out of the land of egypt, from the iron furnace, saying, obey my voice, and do them, according to all which i command you: so shall ye be my people, and i will be your god:\n",
      "and i have made my covenant with your fathers in egypt, and i have made an end of speaking unto them: i have not commanded them that they should make my two eyes to be my gods.\n",
      "blessed [are]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ogwu ubọọn̄ oneniyaka ido siba ibe, “sà gwun̄ nte uwu kwun̄ ìkup me owa?” siba ofọfọọk ibe ke ọmọ òwa me jeruselem okupbe, mije, ìkikeek ibe, usini mgbọ, cherekeyi, ke ebi uwu kè ijeren mêniyaka irek mkpulu nte nte kan̄ inyi ọmọ.\"\n",
    "\n",
    "ob_train_sent = \"ogwu ubọọn̄ oneniyaka ido siba ibe, “sà gwun̄ nte uwu kwun̄ ìkup me owa?” siba ofọfọọk ibe ke ọmọ òwa me jeruselem okupbe, mije, ìkikeek ibe, usini mgbọ, cherekeyi, ke ebi uwu kè ijeren mêniyaka irek mkpulu nte nte kan̄ inyi ọmọ.\"\n",
    "en_train_sent = \"and the king said, and where [is] thy master’s son? and ziba said unto the king, behold, he abideth at jerusalem: for he said, to day shall the house of israel restore me the kingdom of my father.\"\n",
    "print(en_train_sent)\n",
    "print(translate(transformer, ob_train_sent))\n",
    "ob_test_sent = \"eyi nnyibe ebi nte nte kinyi ida ibe esun̄, mgbọ nsan̄abe ema isibi me ijipiti, me emen ukan̄ ikala okwukwut.” mgbọ ya, ntumu inyi ema ibe, “ìgban̄ utọn̄ me ida n̄a, mè ìrọ inu geelek ntọbe inyi enyi, ke enyi mêre ebi n̄a, emi nrere awaji kinyi.\"\n",
    "en_test_sent = \"which i commanded your fathers in the day [that] i brought them forth out of the land of egypt, from the iron furnace, saying, obey my voice, and do them, according to all which i command you: so shall ye be my people, and i will be your god:\"\n",
    "print(en_test_sent)\n",
    "print(translate(transformer, ob_test_sent))\n",
    "print(translate(transformer, 'Jisọs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE TRANSLATE ACTUALLY WORK !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3110\n"
     ]
    }
   ],
   "source": [
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])\n",
    "\n",
    "# def test_model(m):\n",
    "#     preds = []\n",
    "#     refs = []\n",
    "#     for idx in tqdm(range(len(test['Obolo']))):\n",
    "#         ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "#         refs.append(en)\n",
    "#         pred = translate(m, ob)\n",
    "#         preds.append(pred)\n",
    "#     print(len(preds), len(refs))\n",
    "#     chrf_plusplus = chrf.compute(predictions=preds, references=refs, word_order=2)\n",
    "#     other_metrics = metrics.compute(predictions=preds, references=refs)\n",
    "#     return (chrf_plusplus, other_metrics)\n",
    "def test_model(m):\n",
    "    preds = []\n",
    "    refs = []\n",
    "    for idx in tqdm(range(len(test['Obolo']))):\n",
    "        ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "        refs.append(ob)\n",
    "        pred = translate(m, en)\n",
    "        preds.append(pred)\n",
    "    print(len(preds), len(refs))\n",
    "    chrf_plusplus = chrf.compute(predictions=preds, references=refs, word_order=2)\n",
    "    other_metrics = metrics.compute(predictions=preds, references=refs)\n",
    "    return (chrf_plusplus, other_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=7165, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(7165, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:35<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 30.516298886128602, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 32.45739209424741,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.08514677345229262,\n",
       "  'precisions': [0.4488691700032464,\n",
       "   0.1768126681379577,\n",
       "   0.07375519195520204,\n",
       "   0.03397998487433385],\n",
       "  'brevity_penalty': 0.7169782181115002,\n",
       "  'length_ratio': 0.750350891438249,\n",
       "  'translation_length': 64687,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.3889647026647469,\n",
       "  'rouge2': 0.16318169443437253,\n",
       "  'rougeL': 0.3200305096034983,\n",
       "  'rougeLsum': 0.32007272994949043,\n",
       "  'meteor': 0.2585001217061493,\n",
       "  'google_bleu': 0.13797724700696884})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:57<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 33.707072513258616, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 35.69080451580043,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.1135963998447183,\n",
       "  'precisions': [0.4733752433605303,\n",
       "   0.20679685204941478,\n",
       "   0.09910258269289639,\n",
       "   0.052861732008005785],\n",
       "  'brevity_penalty': 0.7548672974495537,\n",
       "  'length_ratio': 0.7805101555522045,\n",
       "  'translation_length': 67287,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.4196666534460921,\n",
       "  'rouge2': 0.1952813313305131,\n",
       "  'rougeL': 0.3483940526167095,\n",
       "  'rougeLsum': 0.3483670493974116,\n",
       "  'meteor': 0.28754652859487134,\n",
       "  'google_bleu': 0.1612627481602423})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:13<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 34.76738466645053, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 36.876217675446675,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12051817598542783,\n",
       "  'precisions': [0.4817572926764784,\n",
       "   0.21019672531769307,\n",
       "   0.10451465114059368,\n",
       "   0.05782380667861648],\n",
       "  'brevity_penalty': 0.7662456564960001,\n",
       "  'length_ratio': 0.7897319305408949,\n",
       "  'translation_length': 68082,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.43024060661192864,\n",
       "  'rouge2': 0.20276996389698157,\n",
       "  'rougeL': 0.3570670160332623,\n",
       "  'rougeLsum': 0.35703934271383075,\n",
       "  'meteor': 0.2964680585451917,\n",
       "  'google_bleu': 0.16744847739157181})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:14<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 35.147126588596635, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 37.30797055276097,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12211214412556817,\n",
       "  'precisions': [0.4853189785568111,\n",
       "   0.21581513019869183,\n",
       "   0.10785353778892211,\n",
       "   0.05994564123213207],\n",
       "  'brevity_penalty': 0.7569785349143128,\n",
       "  'length_ratio': 0.7822153139463397,\n",
       "  'translation_length': 67434,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.43116696564966855,\n",
       "  'rouge2': 0.20530462154652435,\n",
       "  'rougeL': 0.3563588842973261,\n",
       "  'rougeLsum': 0.35639660929779743,\n",
       "  'meteor': 0.29519869143623506,\n",
       "  'google_bleu': 0.1688868872665213})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [07:11<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'score': 35.11386248402468, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       " {'score': 37.28254210034655,\n",
       "  'char_order': 6,\n",
       "  'word_order': 0,\n",
       "  'beta': 2,\n",
       "  'bleu': 0.12210709300738926,\n",
       "  'precisions': [0.49233295173826597,\n",
       "   0.21927623945561164,\n",
       "   0.1102373790217107,\n",
       "   0.06166535742340927],\n",
       "  'brevity_penalty': 0.7418835466763627,\n",
       "  'length_ratio': 0.770082009998956,\n",
       "  'translation_length': 66388,\n",
       "  'reference_length': 86209,\n",
       "  'rouge1': 0.4314226654070229,\n",
       "  'rouge2': 0.2073275724218821,\n",
       "  'rougeL': 0.35928689387858537,\n",
       "  'rougeLsum': 0.35902913114981283,\n",
       "  'meteor': 0.29672718439663953,\n",
       "  'google_bleu': 0.16960727160244132})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "for epoch in [10,20,30,40,50]:\n",
    "    model = torch.load(f'checkpoints/transformer_english_to_obolo_custom_{epoch}_epochs.pt').to(DEVICE)\n",
    "    models.append(model)\n",
    "display(models[0])\n",
    "scores = []\n",
    "for mod in models:\n",
    "    score = test_model(mod)\n",
    "    display(score)\n",
    "    scores.append(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'score': 30.516298886128602, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 32.45739209424741,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.08514677345229262,\n",
       "   'precisions': [0.4488691700032464,\n",
       "    0.1768126681379577,\n",
       "    0.07375519195520204,\n",
       "    0.03397998487433385],\n",
       "   'brevity_penalty': 0.7169782181115002,\n",
       "   'length_ratio': 0.750350891438249,\n",
       "   'translation_length': 64687,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.3889647026647469,\n",
       "   'rouge2': 0.16318169443437253,\n",
       "   'rougeL': 0.3200305096034983,\n",
       "   'rougeLsum': 0.32007272994949043,\n",
       "   'meteor': 0.2585001217061493,\n",
       "   'google_bleu': 0.13797724700696884}),\n",
       " ({'score': 33.707072513258616, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 35.69080451580043,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.1135963998447183,\n",
       "   'precisions': [0.4733752433605303,\n",
       "    0.20679685204941478,\n",
       "    0.09910258269289639,\n",
       "    0.052861732008005785],\n",
       "   'brevity_penalty': 0.7548672974495537,\n",
       "   'length_ratio': 0.7805101555522045,\n",
       "   'translation_length': 67287,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.4196666534460921,\n",
       "   'rouge2': 0.1952813313305131,\n",
       "   'rougeL': 0.3483940526167095,\n",
       "   'rougeLsum': 0.3483670493974116,\n",
       "   'meteor': 0.28754652859487134,\n",
       "   'google_bleu': 0.1612627481602423}),\n",
       " ({'score': 34.76738466645053, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 36.876217675446675,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12051817598542783,\n",
       "   'precisions': [0.4817572926764784,\n",
       "    0.21019672531769307,\n",
       "    0.10451465114059368,\n",
       "    0.05782380667861648],\n",
       "   'brevity_penalty': 0.7662456564960001,\n",
       "   'length_ratio': 0.7897319305408949,\n",
       "   'translation_length': 68082,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.43024060661192864,\n",
       "   'rouge2': 0.20276996389698157,\n",
       "   'rougeL': 0.3570670160332623,\n",
       "   'rougeLsum': 0.35703934271383075,\n",
       "   'meteor': 0.2964680585451917,\n",
       "   'google_bleu': 0.16744847739157181}),\n",
       " ({'score': 35.147126588596635, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 37.30797055276097,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12211214412556817,\n",
       "   'precisions': [0.4853189785568111,\n",
       "    0.21581513019869183,\n",
       "    0.10785353778892211,\n",
       "    0.05994564123213207],\n",
       "   'brevity_penalty': 0.7569785349143128,\n",
       "   'length_ratio': 0.7822153139463397,\n",
       "   'translation_length': 67434,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.43116696564966855,\n",
       "   'rouge2': 0.20530462154652435,\n",
       "   'rougeL': 0.3563588842973261,\n",
       "   'rougeLsum': 0.35639660929779743,\n",
       "   'meteor': 0.29519869143623506,\n",
       "   'google_bleu': 0.1688868872665213}),\n",
       " ({'score': 35.11386248402468, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 37.28254210034655,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.12210709300738926,\n",
       "   'precisions': [0.49233295173826597,\n",
       "    0.21927623945561164,\n",
       "    0.1102373790217107,\n",
       "    0.06166535742340927],\n",
       "   'brevity_penalty': 0.7418835466763627,\n",
       "   'length_ratio': 0.770082009998956,\n",
       "   'translation_length': 66388,\n",
       "   'reference_length': 86209,\n",
       "   'rouge1': 0.4314226654070229,\n",
       "   'rouge2': 0.2073275724218821,\n",
       "   'rougeL': 0.35928689387858537,\n",
       "   'rougeLsum': 0.35902913114981283,\n",
       "   'meteor': 0.29672718439663953,\n",
       "   'google_bleu': 0.16960727160244132})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:42<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 33.6596090739384,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.11152622811206186,\n",
       " 'precisions': [0.3960213311587283,\n",
       "  0.15589433362402993,\n",
       "  0.07046159791763756,\n",
       "  0.0355636772561147],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1587775249605232,\n",
       " 'translation_length': 93197,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.378588728210996,\n",
       " 'rouge2': 0.14502504247389858,\n",
       " 'rougeL': 0.32141031622794514,\n",
       " 'rougeLsum': 0.32135055941369345,\n",
       " 'meteor': 0.32787793097157697,\n",
       " 'google_bleu': 0.16055082533221088}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_10_epoch_custom = torch.load('transformer_obolo_to_english_custom.pt').to(DEVICE)\n",
    "score = test_model(orig_10_epoch_custom)\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    }
   ],
   "source": [
    "print(len(preds), len(refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 30.43952826900615,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.0822760096610319,\n",
       " 'precisions': [0.34278131844280896,\n",
       "  0.11676725534672716,\n",
       "  0.04780428948846498,\n",
       "  0.023949022794337766],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.2602981585785868,\n",
       " 'translation_length': 101362,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.3352499302267455,\n",
       " 'rouge2': 0.11275906915007564,\n",
       " 'rougeL': 0.27644615250839405,\n",
       " 'rougeLsum': 0.2763975206470654,\n",
       " 'meteor': 0.28851067939375274,\n",
       " 'google_bleu': 0.13259436788496107}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = metrics.compute(predictions=preds, references=refs)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
