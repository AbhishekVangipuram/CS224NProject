{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from evaluate import load, combine\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer import *\n",
    "from dataset import *\n",
    "\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "# from custom_tokenizers.tokenizerv1 import parse_sentence\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7165\n",
      "50257\n",
      "cuda\n",
      "en ob\n"
     ]
    }
   ],
   "source": [
    "# get data \n",
    "train = load_dataset('csv', data_files='../data/train.csv')['train']\n",
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "VAL_CUTOFF = 500 # random choice for val loss, full test set is 3110, take 500 away for validation only. \n",
    "val = test[:VAL_CUTOFF]\n",
    "test = test[VAL_CUTOFF:]\n",
    "\n",
    "# obolo_tokenizer = PreTrainedTokenizerFast(tokenizer_file='../custom_tokenizers/obolo-bpe-tokenizer.json', padding='left')\n",
    "english_tokenizer = AutoTokenizer.from_pretrained('gpt2', padding='left')\n",
    "\n",
    "# from custom_tokenizers.tokenizerv2 import parse_sentence\n",
    "from custom_tokenizers.dt_tokenizer import parse_sentence\n",
    "# # we construct this vocab by calculating tokens from train data\n",
    "# obolo_vocab_sents = [set(parse_sentence(s)) for s in train['Obolo']]\n",
    "# obolo_vocab = set()\n",
    "# for sent in obolo_vocab_sents:\n",
    "#     obolo_vocab.update(sent)\n",
    "# obolo_vocab = special_tokens + list(obolo_vocab)\n",
    "# obolo_vocab = {token:idx for idx, token in enumerate(obolo_vocab)}\n",
    "\n",
    "# # Serialize data into file:\n",
    "# # json.dump( obolo_vocab, open( \"../custom_tokenizers/custom_obolo_tokenizer_vocab_2.json\", 'w' ) )\n",
    "# json.dump( obolo_vocab, open( \"../custom_tokenizers/custom_obolo_detokenizer_vocab.json\", 'w' ) )\n",
    "\n",
    "\n",
    "# Read data from file:\n",
    "# obolo_vocab = json.load( open( \"../custom_tokenizers/custom_obolo_tokenizer_vocab_2.json\" ) )\n",
    "obolo_vocab = json.load( open( \"../custom_tokenizers/custom_obolo_detokenizer_vocab.json\" ) )\n",
    "\n",
    "\n",
    "print(len(obolo_vocab))\n",
    "print(len(english_tokenizer.vocab))\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "# token_transform[SRC_LANGUAGE] = parse_sentence\n",
    "# token_transform[TGT_LANGUAGE] = english_tokenizer\n",
    "\n",
    "# vocab_transform[SRC_LANGUAGE] = obolo_vocab \n",
    "# vocab_transform[TGT_LANGUAGE] = english_tokenizer.vocab\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'ob'\n",
    "token_transform[SRC_LANGUAGE] = english_tokenizer\n",
    "token_transform[TGT_LANGUAGE] = parse_sentence\n",
    "\n",
    "vocab_transform[SRC_LANGUAGE] = english_tokenizer.vocab \n",
    "vocab_transform[TGT_LANGUAGE] = obolo_vocab\n",
    "\n",
    "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#   vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "init_text_transform(token_transform, SRC_LANGUAGE, TGT_LANGUAGE)\n",
    "\n",
    "# change this due to custom tokenizer\n",
    "# init_text_transform(token_transform)\n",
    "# text_transform[SRC_LANGUAGE] = sequential_transforms((lambda text: [obolo_vocab[token] if token in obolo_vocab else UNK_IDX for token in token_transform[SRC_LANGUAGE](text)]), # input to tokens to ids\n",
    "#                                                      tensor_transform)                                                                                                          # add BOS/EOS and create tensor\n",
    "\n",
    "# text_transform[TGT_LANGUAGE] = sequential_transforms((lambda text: token_transform[TGT_LANGUAGE](text).get('input_ids')),\n",
    "#                                                      tensor_transform)    \n",
    "\n",
    "text_transform[TGT_LANGUAGE] = sequential_transforms((lambda text: [obolo_vocab[token] if token in obolo_vocab else UNK_IDX for token in token_transform[TGT_LANGUAGE](text)]), # input to tokens to ids\n",
    "                                                     tensor_transform)                                                                                                          # add BOS/EOS and create tensor\n",
    "\n",
    "text_transform[SRC_LANGUAGE] = sequential_transforms((lambda text: token_transform[SRC_LANGUAGE](text).get('input_ids')),\n",
    "                                                     tensor_transform)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eya orọ, nnenikana isi lek ogwukaan̄-ene awaji, mè ito ito inyi, mè iriaak uriaak, mè ibeek mbeek, mè ijin otu, mè itap ofọnti ufieejit, mè ifuun̄ lek me ntọn̄.\n",
      "['e', 'ya', 'o', 'rọ', ',', 'n', 'neni', 'kana', 'i', 'si', 'lek', 'ogwukaan̄', '-', 'e', 'ne', 'awaji', ',', 'mè', 'i', 'to', 'i', 'to', 'i', 'nyi', ',', 'mè', 'i', 'riaak', 'uriaak', ',', 'mè', 'i', 'beek', 'm', 'beek', ',', 'mè', 'i', 'jin', 'o', 'tu', ',', 'mè', 'i', 'tap', 'ofọnti', 'ufieejit', ',', 'mè', 'i', 'fuun̄', 'lek', 'me', 'n', 'tọn̄', '.']\n",
      "tensor([   1, 3663, 4948, 2148, 2510, 2491, 6404, 4761, 6466, 1347, 5593, 5110,\n",
      "        5583, 2024, 3663, 1519, 3486, 2491, 3865, 1347, 1128, 1347, 1128, 1347,\n",
      "         443, 2491, 3865, 1347, 5579,  136, 2491, 3865, 1347, 3847, 4775, 3847,\n",
      "        2491, 3865, 1347, 3084, 2148, 1164, 2491, 3865, 1347, 6278, 5203, 6492,\n",
      "        2491, 3865, 1347,  278, 5110, 3449, 6404, 2887, 6770,    2])\n",
      "True\n",
      "and i set my face unto the lord god, to seek by prayer and supplications, with fasting, and sackcloth, and ashes:\n",
      "tensor([    1,   392,  1312,   900,   616,  1986, 12722,   262, 15876,  5770,\n",
      "           11,   284,  5380,   416, 11443,   290,   802,   677,   602,    11,\n",
      "          351, 24845,    11,   290, 23704, 44905,    11,   290, 29914,    25,\n",
      "            2])\n"
     ]
    }
   ],
   "source": [
    "ob_sent, en_sent = train['Obolo'][0], train['English'][0]\n",
    "print(ob_sent)\n",
    "print(parse_sentence(ob_sent))\n",
    "print(text_transform[SRC_LANGUAGE](ob_sent))\n",
    "print([obolo_vocab[token] for token in token_transform[SRC_LANGUAGE](ob_sent)] == list(text_transform[SRC_LANGUAGE](ob_sent))[1:-1])\n",
    "print(en_sent)\n",
    "print(text_transform[TGT_LANGUAGE](en_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(obolo_vocab)\n",
    "print(SRC_VOCAB_SIZE)\n",
    "TGT_VOCAB_SIZE = english_tokenizer.vocab_size\n",
    "# ORIGINAL TRANSFORMER CONFIGURATION\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# TWEAKS ARE BAD, JUST USE DEFAULT CONFIG\n",
    "# EMB_SIZE = 512\n",
    "# NHEAD = 16\n",
    "# FFN_HID_DIM = 512\n",
    "# BATCH_SIZE = 64\n",
    "# NUM_ENCODER_LAYERS = 6\n",
    "# NUM_DECODER_LAYERS = 6\n",
    "\n",
    "# train_dataloader = generate_dataloader(train['Obolo'], train['English'], BATCH_SIZE)\n",
    "# val_dataloader = generate_dataloader(val['Obolo'], val['English'], BATCH_SIZE)\n",
    "# test_dataloader = generate_dataloader(test['Obolo'], test['English'], BATCH_SIZE)\n",
    "train_dataloader = generate_dataloader(train['English'], train['Obolo'], BATCH_SIZE)\n",
    "val_dataloader = generate_dataloader(val['English'], val['Obolo'], BATCH_SIZE)\n",
    "test_dataloader = generate_dataloader(test['English'], test['Obolo'], BATCH_SIZE)\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "# optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=50257, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(7150, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.98)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-09\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transformer)\n",
    "display(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "        # save vram \n",
    "        del src, tgt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 438/438 [04:31<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.795, Val loss: 4.473, Epoch time = 284.880s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 4.188, Val loss: 3.871, Epoch time = 277.164s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:30<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 3.739, Val loss: 3.526, Epoch time = 283.914s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 3.433, Val loss: 3.289, Epoch time = 277.622s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 3.198, Val loss: 3.108, Epoch time = 277.310s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 3.006, Val loss: 2.964, Epoch time = 275.477s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 2.843, Val loss: 2.853, Epoch time = 276.150s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 2.701, Val loss: 2.762, Epoch time = 275.433s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:21<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 2.576, Val loss: 2.688, Epoch time = 275.226s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 2.464, Val loss: 2.641, Epoch time = 276.120s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 2.363, Val loss: 2.594, Epoch time = 277.910s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 2.270, Val loss: 2.555, Epoch time = 276.418s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 2.181, Val loss: 2.530, Epoch time = 277.328s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 2.104, Val loss: 2.486, Epoch time = 278.321s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 2.029, Val loss: 2.449, Epoch time = 276.970s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.958, Val loss: 2.441, Epoch time = 276.513s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 1.895, Val loss: 2.430, Epoch time = 277.281s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 1.834, Val loss: 2.410, Epoch time = 276.435s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 1.773, Val loss: 2.397, Epoch time = 277.393s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 1.711, Val loss: 2.402, Epoch time = 277.171s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 1.658, Val loss: 2.427, Epoch time = 277.587s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 1.607, Val loss: 2.424, Epoch time = 276.638s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:26<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 1.556, Val loss: 2.417, Epoch time = 279.712s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:25<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 1.504, Val loss: 2.427, Epoch time = 279.438s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 1.457, Val loss: 2.421, Epoch time = 278.202s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 1.412, Val loss: 2.442, Epoch time = 278.304s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 1.370, Val loss: 2.455, Epoch time = 278.219s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:27<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 1.326, Val loss: 2.462, Epoch time = 280.813s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:26<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 1.283, Val loss: 2.491, Epoch time = 279.804s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:30<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 1.247, Val loss: 2.508, Epoch time = 284.251s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:27<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 1.208, Val loss: 2.527, Epoch time = 281.199s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 1.171, Val loss: 2.555, Epoch time = 278.483s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 1.137, Val loss: 2.550, Epoch time = 277.735s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 1.102, Val loss: 2.571, Epoch time = 276.863s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 1.067, Val loss: 2.586, Epoch time = 277.036s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:29<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 1.035, Val loss: 2.598, Epoch time = 282.811s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 1.003, Val loss: 2.627, Epoch time = 277.351s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 0.971, Val loss: 2.646, Epoch time = 277.076s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 0.941, Val loss: 2.671, Epoch time = 277.653s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 0.913, Val loss: 2.698, Epoch time = 275.998s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 0.885, Val loss: 2.719, Epoch time = 276.671s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:25<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 0.860, Val loss: 2.736, Epoch time = 278.543s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:22<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 0.832, Val loss: 2.770, Epoch time = 276.420s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 0.806, Val loss: 2.772, Epoch time = 278.252s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:25<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 0.782, Val loss: 2.779, Epoch time = 278.662s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:23<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 0.761, Val loss: 2.817, Epoch time = 277.286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 0.735, Val loss: 2.833, Epoch time = 278.355s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:26<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 0.712, Val loss: 2.855, Epoch time = 279.538s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 0.691, Val loss: 2.879, Epoch time = 277.434s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.670, Val loss: 2.911, Epoch time = 277.980s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# NUM_EPOCHS = 10\n",
    "NUM_EPOCHS = 50 \n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(transformer, f'checkpoints/transformer_english_to_obolo_custom_{epoch}_epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), 'transformer_obolo_to_english_custom_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer, 'transformer_obolo_to_english_custom.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=50257, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(6864, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=torch.load('transformer_obolo_to_english_custom.pt')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        # print(out)\n",
    "        # print(english_tokenizer.decode(out))\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        # print(next_word)\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # save vram\n",
    "        del tgt_mask\n",
    "        torch.cuda.empty_cache()\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    \n",
    "    return token_transform[TGT_LANGUAGE].decode(tgt_tokens[1:-1])\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_sentence = \"ire, emi okumugwem mâtap oke me etete anam ebi ijeren mè echi ebi ijipiti. anam geege me etete echi ebi ijeren ìkpokwu\"\n",
    "# src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "# print(list(src.numpy().flatten()), src.shape)\n",
    "# print(token_transform[SRC_LANGUAGE].decode(src.numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mgbọ yaage îmun̄be ife chi egwookbe, ibebene ikaan̄ ulọk me lek kiban̄, mè iria osat isi lek kiban̄ me kalidia.\n",
      "and it came to pass, when they saw that they had seen, that they sent to the sea, and sent them to the chaldeans, and sent to the chaldeans.\n",
      "and as soon as she saw them with her eyes, she doted upon them, and sent messengers unto them into chaldea.\n"
     ]
    }
   ],
   "source": [
    "ob, en = test['Obolo'][100], test['English'][100]\n",
    "print(ob)\n",
    "print(translate(m, ob))\n",
    "print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the king said, and where [is] thy master’s son? and ziba said unto the king, behold, he abideth at jerusalem: for he said, to day shall the house of israel restore me the kingdom of my father.\n",
      "and the king said unto the woman, how [is] this thy son, that he may be done unto this house of israel? and he said, nay; for the son of man, i will surely rend the kingdom from the kingdom of israel.\n",
      "which i commanded your fathers in the day [that] i brought them forth out of the land of egypt, from the iron furnace, saying, obey my voice, and do them, according to all which i command you: so shall ye be my people, and i will be your god:\n",
      "and i have made my covenant with your fathers in egypt, and i have made an end of speaking unto them: i have not commanded them that they should make my two eyes to be my gods.\n",
      "blessed [are]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ogwu ubọọn̄ oneniyaka ido siba ibe, “sà gwun̄ nte uwu kwun̄ ìkup me owa?” siba ofọfọọk ibe ke ọmọ òwa me jeruselem okupbe, mije, ìkikeek ibe, usini mgbọ, cherekeyi, ke ebi uwu kè ijeren mêniyaka irek mkpulu nte nte kan̄ inyi ọmọ.\"\n",
    "\n",
    "ob_train_sent = \"ogwu ubọọn̄ oneniyaka ido siba ibe, “sà gwun̄ nte uwu kwun̄ ìkup me owa?” siba ofọfọọk ibe ke ọmọ òwa me jeruselem okupbe, mije, ìkikeek ibe, usini mgbọ, cherekeyi, ke ebi uwu kè ijeren mêniyaka irek mkpulu nte nte kan̄ inyi ọmọ.\"\n",
    "en_train_sent = \"and the king said, and where [is] thy master’s son? and ziba said unto the king, behold, he abideth at jerusalem: for he said, to day shall the house of israel restore me the kingdom of my father.\"\n",
    "print(en_train_sent)\n",
    "print(translate(transformer, ob_train_sent))\n",
    "ob_test_sent = \"eyi nnyibe ebi nte nte kinyi ida ibe esun̄, mgbọ nsan̄abe ema isibi me ijipiti, me emen ukan̄ ikala okwukwut.” mgbọ ya, ntumu inyi ema ibe, “ìgban̄ utọn̄ me ida n̄a, mè ìrọ inu geelek ntọbe inyi enyi, ke enyi mêre ebi n̄a, emi nrere awaji kinyi.\"\n",
    "en_test_sent = \"which i commanded your fathers in the day [that] i brought them forth out of the land of egypt, from the iron furnace, saying, obey my voice, and do them, according to all which i command you: so shall ye be my people, and i will be your god:\"\n",
    "print(en_test_sent)\n",
    "print(translate(transformer, ob_test_sent))\n",
    "print(translate(transformer, 'Jisọs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE TRANSLATE ACTUALLY WORK !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3110\n"
     ]
    }
   ],
   "source": [
    "test = load_dataset('csv', data_files='../data/test.csv')['train']\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])\n",
    "\n",
    "def test_model(m):\n",
    "    preds = []\n",
    "    refs = []\n",
    "    for idx in tqdm(range(len(test['Obolo']))):\n",
    "        ob, en = test['Obolo'][idx], test['English'][idx]\n",
    "        refs.append(en)\n",
    "        pred = translate(m, ob)\n",
    "        preds.append(pred)\n",
    "    print(len(preds), len(refs))\n",
    "    chrf_plusplus = chrf.compute(predictions=preds, references=refs, word_order=2)\n",
    "    other_metrics = metrics.compute(predictions=preds, references=refs)\n",
    "    return (chrf_plusplus, other_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m50\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints/transformer_obolo_to_english_custom2_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epochs.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      4\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m      5\u001b[0m display(models[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1026\u001b[0m                      map_location,\n\u001b[0;32m   1027\u001b[0m                      pickle_module,\n\u001b[0;32m   1028\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1029\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1451\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1415\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1416\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:1390\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1390\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1391\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1392\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1395\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:390\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 390\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abhiv\\miniconda3\\envs\\cs224n-gpu\\lib\\site-packages\\torch\\_utils.py:117\u001b[0m, in \u001b[0;36m_cuda\u001b[1;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m     )\n\u001b[1;32m--> 117\u001b[0m     \u001b[43muntyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for epoch in [10,20,30,40,50]:\n",
    "    model = torch.load(f'checkpoints/transformer_obolo_to_english_custom2_{epoch}_epochs.pt').to(DEVICE)\n",
    "    models.append(model)\n",
    "display(models[0])\n",
    "scores = []\n",
    "for mod in models:\n",
    "    score = test_model(mod)\n",
    "    display(score)\n",
    "    scores.append(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'score': 33.14887289176948, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 33.94522941130094,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.10615131528855178,\n",
       "   'precisions': [0.37927541956589994,\n",
       "    0.1489445814217201,\n",
       "    0.06685701453273876,\n",
       "    0.03361825242291234],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.2276101309261815,\n",
       "   'translation_length': 98733,\n",
       "   'reference_length': 80427,\n",
       "   'rouge1': 0.37320652389898057,\n",
       "   'rouge2': 0.1430445557839643,\n",
       "   'rougeL': 0.316166689351148,\n",
       "   'rougeLsum': 0.31598264093105866,\n",
       "   'meteor': 0.32309606902943644,\n",
       "   'google_bleu': 0.15597258118889762}),\n",
       " ({'score': 36.58625994321825, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 37.60193081439757,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.13759957722373378,\n",
       "   'precisions': [0.42630054656707966,\n",
       "    0.18309874938365683,\n",
       "    0.09121972617920716,\n",
       "    0.050347552847076746],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.141979683439641,\n",
       "   'translation_length': 91846,\n",
       "   'reference_length': 80427,\n",
       "   'rouge1': 0.41268027475024494,\n",
       "   'rouge2': 0.17457984464766912,\n",
       "   'rougeL': 0.3496035173312554,\n",
       "   'rougeLsum': 0.3493703238288245,\n",
       "   'meteor': 0.356179574105773,\n",
       "   'google_bleu': 0.18288890090869753}),\n",
       " ({'score': 38.43958448439957, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 39.5971501154129,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.13956757032955844,\n",
       "   'precisions': [0.4187821890587615,\n",
       "    0.18206527398829483,\n",
       "    0.09355998972338786,\n",
       "    0.053190317820408346],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.226404068285526,\n",
       "   'translation_length': 98636,\n",
       "   'reference_length': 80427,\n",
       "   'rouge1': 0.4210822993181115,\n",
       "   'rouge2': 0.1816383871353319,\n",
       "   'rougeL': 0.35332858923817767,\n",
       "   'rougeLsum': 0.35341266954093215,\n",
       "   'meteor': 0.37135268802998245,\n",
       "   'google_bleu': 0.1855327528383742}),\n",
       " ({'score': 38.49924043564366, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 39.708407365154414,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.13838354030451644,\n",
       "   'precisions': [0.4170478927978624,\n",
       "    0.18092604528348963,\n",
       "    0.09265472730381262,\n",
       "    0.05245454745311847],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.2284929190445995,\n",
       "   'translation_length': 98804,\n",
       "   'reference_length': 80427,\n",
       "   'rouge1': 0.4187983352349158,\n",
       "   'rouge2': 0.18173869157410452,\n",
       "   'rougeL': 0.3499244368277429,\n",
       "   'rougeLsum': 0.34999375801502675,\n",
       "   'meteor': 0.3661395121127491,\n",
       "   'google_bleu': 0.18442971229650865}),\n",
       " ({'score': 37.87360312596647, 'char_order': 6, 'word_order': 2, 'beta': 2},\n",
       "  {'score': 39.21605259469973,\n",
       "   'char_order': 6,\n",
       "   'word_order': 0,\n",
       "   'beta': 2,\n",
       "   'bleu': 0.1373916252057474,\n",
       "   'precisions': [0.4199449502434893,\n",
       "    0.17947740881872618,\n",
       "    0.09131555356342447,\n",
       "    0.051771903497633616],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.1744812065599861,\n",
       "   'translation_length': 94460,\n",
       "   'reference_length': 80427,\n",
       "   'rouge1': 0.4121233360711696,\n",
       "   'rouge2': 0.17595779493226876,\n",
       "   'rougeL': 0.3445745605013277,\n",
       "   'rougeLsum': 0.344485418197156,\n",
       "   'meteor': 0.3538899783367709,\n",
       "   'google_bleu': 0.1822925500339213})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [08:42<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 33.6596090739384,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.11152622811206186,\n",
       " 'precisions': [0.3960213311587283,\n",
       "  0.15589433362402993,\n",
       "  0.07046159791763756,\n",
       "  0.0355636772561147],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.1587775249605232,\n",
       " 'translation_length': 93197,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.378588728210996,\n",
       " 'rouge2': 0.14502504247389858,\n",
       " 'rougeL': 0.32141031622794514,\n",
       " 'rougeLsum': 0.32135055941369345,\n",
       " 'meteor': 0.32787793097157697,\n",
       " 'google_bleu': 0.16055082533221088}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_10_epoch_custom = torch.load('transformer_obolo_to_english_custom.pt').to(DEVICE)\n",
    "score = test_model(orig_10_epoch_custom)\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 2610\n"
     ]
    }
   ],
   "source": [
    "print(len(preds), len(refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\abhiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "chrf = load('chrf')\n",
    "gleu = load('google_bleu')\n",
    "rouge = load('rouge') \n",
    "bleu = load('bleu')\n",
    "meteor = load('meteor')\n",
    "metrics = combine([chrf, bleu, rouge, meteor, gleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 30.43952826900615,\n",
       " 'char_order': 6,\n",
       " 'word_order': 0,\n",
       " 'beta': 2,\n",
       " 'bleu': 0.0822760096610319,\n",
       " 'precisions': [0.34278131844280896,\n",
       "  0.11676725534672716,\n",
       "  0.04780428948846498,\n",
       "  0.023949022794337766],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.2602981585785868,\n",
       " 'translation_length': 101362,\n",
       " 'reference_length': 80427,\n",
       " 'rouge1': 0.3352499302267455,\n",
       " 'rouge2': 0.11275906915007564,\n",
       " 'rougeL': 0.27644615250839405,\n",
       " 'rougeLsum': 0.2763975206470654,\n",
       " 'meteor': 0.28851067939375274,\n",
       " 'google_bleu': 0.13259436788496107}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = metrics.compute(predictions=preds, references=refs)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
